{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9d0eb552",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\statsmodels\\tsa\\base\\tsa_model.py:7: FutureWarning: pandas.Int64Index is deprecated and will be removed from pandas in a future version. Use pandas.Index with the appropriate dtype instead.\n",
      "  from pandas import (to_datetime, Int64Index, DatetimeIndex, Period,\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\statsmodels\\tsa\\base\\tsa_model.py:7: FutureWarning: pandas.Float64Index is deprecated and will be removed from pandas in a future version. Use pandas.Index with the appropriate dtype instead.\n",
      "  from pandas import (to_datetime, Int64Index, DatetimeIndex, Period,\n"
     ]
    }
   ],
   "source": [
    "#Import Libraries\n",
    "import os\n",
    "import pandas as pd \n",
    "import numpy as np \n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns \n",
    "import statsmodels.api as sm\n",
    "from sklearn.linear_model import LinearRegression,LogisticRegressionCV,LassoCV,ElasticNet,ElasticNetCV,RidgeCV,RidgeClassifierCV,ridge_regression\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "from statsmodels.formula.api import ols\n",
    "from statsmodels.stats.anova import anova_lm\n",
    "from statsmodels.stats.outliers_influence import variance_inflation_factor\n",
    "from sklearn.model_selection import KFold, StratifiedKFold, train_test_split, cross_val_score,cross_val_predict,RepeatedStratifiedKFold,RepeatedKFold\n",
    "from sklearn.metrics import r2_score, mean_squared_error, confusion_matrix, ConfusionMatrixDisplay\n",
    "from sklearn.ensemble import GradientBoostingClassifier, GradientBoostingRegressor, RandomForestClassifier, RandomForestRegressor\n",
    "#need \"pip install scikit-optimize\"\n",
    "from skopt.searchcv import BayesSearchCV\n",
    "from skopt.space import Integer, Real, Categorical \n",
    "from skopt.utils import use_named_args\n",
    "from skopt import gp_minimize\n",
    "from timeit import default_timer as timer\n",
    "from sklearn import tree\n",
    "import graphviz\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e7e0cb9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#all the regression models\n",
    "def graph_result(X,Y_test,Y_pred):\n",
    "    x_ax = range(len(X))\n",
    "    plt.scatter(x_ax, Y_test, s=5, color=\"navy\", label=\"original\")\n",
    "    plt.plot(x_ax, Y_pred, lw=0.8, color=\"gold\", label=\"predicted\")\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "    return()\n",
    "\n",
    "def run_linear(X,Y,graph=False):\n",
    "    #X = predictors, Y = response, log determines if we are using linear or logistic regression\n",
    "    #first step is to use a Bayes Search algorithm to find the optimal hyperparameters\n",
    "    #define hyperparameters to search   \n",
    "    hyper_params = {\n",
    "        'fit_intercept' : [True,False],\n",
    "        'positive' : [True,False]\n",
    "    }    \n",
    "    cv = KFold(n_splits = 10,shuffle=True,random_state=5440)   #set random_state to make results repeatable\n",
    "    search = BayesSearchCV(\n",
    "        estimator=LinearRegression(),\n",
    "        search_spaces=hyper_params,\n",
    "        n_jobs=-1,\n",
    "        cv=cv,\n",
    "        n_iter=10,\n",
    "        #scoring=\"accuracy\",  -- leave as default which is based on the estimator\n",
    "        verbose=0,\n",
    "        random_state=5440\n",
    "    )\n",
    "    #scale the x predictor values and then run the Bayesian search and capture best parameters\n",
    "    scaler = StandardScaler()\n",
    "    x_scaled = scaler.fit_transform(X)       \n",
    "    search.fit(x_scaled,Y)    \n",
    "    best_params = search.best_params_\n",
    "    print(best_params)\n",
    "    \n",
    "    #X = predictors, Y = response, log determines if we are using linear or logistic regression\n",
    "    x_train,x_test,y_train,y_test = train_test_split(x_scaled,Y,test_size=.24,random_state=5440)   \n",
    "\n",
    "    model = LinearRegression(n_jobs=-1,fit_intercept=best_params['fit_intercept'],positive=best_params['positive'])\n",
    "    model.fit(x_train,y_train)\n",
    "    pred_test = model.predict(x_test)\n",
    "    rmse_test = np.sqrt(mean_squared_error(y_test,pred_test))\n",
    "    r2_test = r2_score(y_test, pred_test)  \n",
    "    \n",
    "    if graph:\n",
    "        graph_result(x_test,y_test,pred_test)\n",
    "    \n",
    "    return(rmse_test,r2_test)\n",
    "    \n",
    "# function for fitting trees of various depths for Random Forests\n",
    "def run_cross_validation_on_regression_RF(X, Y):\n",
    "    #X = predictors, Y = response, log determines if we are using linear or logistic regression\n",
    "    #first step is to use a Bayes Search algorithm to find the optimal hyperparameters\n",
    "    #define hyperparameters to search   \n",
    "    hyper_params = {\n",
    "        'n_estimators': [200, 400, 600, 800, 1000],\n",
    "        'max_depth': (1, 9),\n",
    "        'criterion': ['squared_error'],\n",
    "        'max_features' : [.250,.3333,.375]\n",
    "    }\n",
    "    cv = KFold(n_splits = 5,shuffle=True,random_state=5440)   #set random_state to make results repeatable\n",
    "    search = BayesSearchCV(\n",
    "        estimator=RandomForestRegressor(),\n",
    "        search_spaces=hyper_params,\n",
    "        n_jobs=-1,\n",
    "        cv=cv,\n",
    "        n_iter=100,\n",
    "        #scoring=\"accuracy\",\n",
    "        verbose=0,\n",
    "        random_state=5440\n",
    "    )\n",
    "    \n",
    "    search.fit(X,Y)    \n",
    "    best_params = search.best_params_\n",
    "    print(best_params)\n",
    "    \n",
    "    #now that the best parameters are found, split the data, run on a test dataset and then predict results\n",
    "    x_train,x_test,y_train,y_test = train_test_split(X,Y,test_size=.24,random_state=5440)\n",
    "    model = RandomForestRegressor(n_estimators=best_params['n_estimators'],max_depth=best_params['max_depth']\n",
    "                                   ,criterion=best_params['criterion'],max_features=best_params['max_features'])\n",
    "    model.fit(x_train,y_train)\n",
    "    pred_test = model.predict(x_test)    \n",
    "    rmse_test = np.sqrt(mean_squared_error(y_test,pred_test))\n",
    "    r2_test = r2_score(y_test, pred_test)  \n",
    "    return(rmse_test,r2_test)\n",
    "\n",
    "# function for fitting trees of various depths for Boosted Version\n",
    "def run_cross_validation_on_regression_Boost(X, Y):\n",
    "    #X = predictors, Y = response\n",
    "    #first step is to use a Bayes Search algorithm to find the optimal hyperparameters\n",
    "    #define hyperparameters to search   \n",
    "    hyper_params = {\n",
    "        'n_estimators': [500, 600, 700, 800, 900, 1000],\n",
    "        'max_depth': (1, 9),\n",
    "        'criterion': ['friedman_mse','squared_error'],\n",
    "        'loss' : ['squared_error','huber'],\n",
    "        'max_features' : ['sqrt','log2']\n",
    "    }    \n",
    "    cv = KFold(n_splits = 5,shuffle=True,random_state=5440)   #set random_state to make results repeatable\n",
    "    search = BayesSearchCV(\n",
    "        estimator=GradientBoostingRegressor(),\n",
    "        search_spaces=hyper_params,\n",
    "        n_jobs=-1,\n",
    "        cv=cv,\n",
    "        n_iter=150,\n",
    "        #scoring=\"accuracy\",\n",
    "        verbose=0,\n",
    "        random_state=5440\n",
    "    )\n",
    "    \n",
    "    search.fit(X,Y)    \n",
    "    best_params = search.best_params_\n",
    "    print(best_params)\n",
    "    \n",
    "    #now that the best parameters are found, split the data, run on a test dataset and then predict results\n",
    "    x_train,x_test,y_train,y_test = train_test_split(X,Y,test_size=.24,random_state=5440)\n",
    "    model = GradientBoostingRegressor(n_estimators=best_params['n_estimators'],max_depth=best_params['max_depth']\n",
    "                                   ,criterion=best_params['criterion'],loss=best_params['loss'],max_features=best_params['max_features'])\n",
    "    model.fit(x_train,y_train)\n",
    "    pred_test = model.predict(x_test)\n",
    "    rmse_test = np.sqrt(mean_squared_error(y_test,pred_test))\n",
    "    r2_test = r2_score(y_test, pred_test)  \n",
    "    return(rmse_test,r2_test)\n",
    "\n",
    "#enet regression:  handles E-Net and Lasso\n",
    "def run_enet_regression(X,Y,graph=False,iter_nbr=1000):\n",
    "    #X = predictors, Y = response, log determines if we are using linear or logistic regression\n",
    "    #first step is to use a Bayes Search algorithm to find the optimal hyperparameters\n",
    "    #define hyperparameters to search   \n",
    "    hyper_params = {\n",
    "        'alpha' : [.001,.01,.1,1.0,10.0,100.0,110.0],\n",
    "        'l1_ratio' : [.01,.05,.1,.3,.5,.7,.9,.95,.99,1],\n",
    "        'fit_intercept' : [True,False]\n",
    "    }    \n",
    "    cv = KFold(n_splits = 5,shuffle=True,random_state=5440)   #set random_state to make results repeatable\n",
    "    search = BayesSearchCV(\n",
    "        estimator=ElasticNet(),\n",
    "        search_spaces=hyper_params,\n",
    "        n_jobs=-1,\n",
    "        cv=cv,\n",
    "        n_iter=175,\n",
    "        #scoring=\"accuracy\",  -- leave as default which is based on the estimator\n",
    "        verbose=0,\n",
    "        random_state=5440\n",
    "    )\n",
    "    #scale the x predictor values and then run the Bayesian search and capture best parameters\n",
    "    scaler = StandardScaler()\n",
    "    x_scaled = scaler.fit_transform(X)       \n",
    "    search.fit(x_scaled,Y)    \n",
    "    best_params = search.best_params_\n",
    "    print(best_params)\n",
    "    \n",
    "    #X = predictors, Y = response, log determines if we are using linear or logistic regression\n",
    "    x_train,x_test,y_train,y_test = train_test_split(x_scaled,Y,test_size=.24,random_state=5440)   \n",
    "\n",
    "    model = ElasticNet(fit_intercept=best_params['fit_intercept'],alpha=best_params['alpha'],\n",
    "                         l1_ratio=best_params['l1_ratio'],random_state=5440)\n",
    "    model.fit(x_train,y_train)\n",
    "    pred_test = model.predict(x_test)\n",
    "    rmse_test = np.sqrt(mean_squared_error(y_test,pred_test))\n",
    "    r2_test = r2_score(y_test, pred_test)  \n",
    "    \n",
    "    if graph:\n",
    "        graph_result(x_test,y_test,pred_test)\n",
    "    \n",
    "    return(rmse_test,r2_test)\n",
    "\n",
    "#ridge regression:  handles Ridge separately due to different hyperparameters and lack of feature selection\n",
    "def run_ridge_regression(X,Y,graph=False,iter_nbr=1000):\n",
    "    #X = predictors, Y = response, log determines if we are using linear or logistic regression\n",
    "\n",
    "    #scale the x predictor values and then run the Bayesian search and capture best parameters\n",
    "    scaler = StandardScaler()\n",
    "    x_scaled = scaler.fit_transform(X)       \n",
    "   \n",
    "    cv = RepeatedKFold(n_splits = 5,n_repeats=75,random_state=5440)  \n",
    "    model = RidgeCV(alphas=[.0001,.0005,.001,.005,.01,.05,.1,.5,1.0,5,10,50,100],cv=cv)\n",
    "    model.fit(x_scaled,Y)\n",
    "    print(model.alpha_)\n",
    "    \n",
    "    #X = predictors, Y = response, log determines if we are using linear or logistic regression\n",
    "    x_train,x_test,y_train,y_test = train_test_split(x_scaled,Y,test_size=.24,random_state=5440)   \n",
    "\n",
    "    pred_test = model.predict(x_test)\n",
    "    rmse_test = np.sqrt(mean_squared_error(y_test,pred_test))\n",
    "    r2_test = r2_score(y_test, pred_test)  \n",
    "    \n",
    "    if graph:\n",
    "        graph_result(x_test,y_test,pred_test)\n",
    "    \n",
    "    return(rmse_test,r2_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a7afd417",
   "metadata": {},
   "outputs": [],
   "source": [
    "#models used for classification\n",
    "def run_logistic(X,Y,graph=False,iter_nbr=100):\n",
    "    #X = predictors, Y = response, log determines if we are using linear or logistic regression\n",
    "    #first step is to use a Bayes Search algorithm to find the optimal hyperparameters\n",
    "    #define hyperparameters to search   \n",
    "    hyper_params = {\n",
    "        'fit_intercept' : [True,False],\n",
    "        'solver' : ['newton-cg', 'lbfgs', 'liblinear', 'sag', 'saga']\n",
    "    }    \n",
    "    cv = StratifiedKFold(n_splits = 10,shuffle=True,random_state=5440)   #set random_state to make results repeatable\n",
    "    search = BayesSearchCV(\n",
    "        estimator=LogisticRegressionCV(),\n",
    "        search_spaces=hyper_params,\n",
    "        n_jobs=-1,\n",
    "        cv=cv,\n",
    "        n_iter=50,\n",
    "        scoring=\"accuracy\",\n",
    "        verbose=0,\n",
    "        random_state=5440\n",
    "    )\n",
    "    #scale the x predictor values and then run the Bayesian search and capture best parameters\n",
    "    scaler = StandardScaler()\n",
    "    x_scaled = scaler.fit_transform(X)       \n",
    "    search.fit(x_scaled,Y)    \n",
    "    best_params = search.best_params_\n",
    "    print(best_params)\n",
    "    \n",
    "    #now that the best parameters are found, split the data, run on a test dataset and then predict results\n",
    "    x_train,x_test,y_train,y_test = train_test_split(x_scaled,Y,test_size=.24,random_state=5440)\n",
    "    model = LogisticRegressionCV(cv=cv,fit_intercept=best_params['fit_intercept']\n",
    "                                 ,solver=best_params['solver'],scoring='accuracy',max_iter=iter_nbr,n_jobs=-1)\n",
    "    model.fit(x_train,y_train)\n",
    "    pred_test = model.predict(x_test)\n",
    "    test_score = model.score(x_test,y_test)\n",
    "      \n",
    "    if graph:\n",
    "        cm = confusion_matrix(y_test,pred_test)\n",
    "        disp = ConfusionMatrixDisplay(confusion_matrix=cm,display_labels=model.classes_)\n",
    "        disp.plot(cmap='Greys')\n",
    "        plt.show()\n",
    "\n",
    "    return(test_score)\n",
    "\n",
    "# function for fitting trees of various depths using cross-validation\n",
    "def run_cross_validation_on_classification_RF(X, Y,scoring='accuracy',iter_nbr=500,graph=False):\n",
    "    #X = predictors, Y = response, log determines if we are using linear or logistic regression\n",
    "    #first step is to use a Bayes Search algorithm to find the optimal hyperparameters\n",
    "    #define hyperparameters to search   \n",
    "    hyper_params = {\n",
    "        'n_estimators': [200, 400, 600, 800,  1000],\n",
    "        'max_depth': (1, 9),\n",
    "        'criterion': ['gini', 'entropy'],\n",
    "        'max_features' : ['sqrt','log2']\n",
    "    }   \n",
    "    cv = StratifiedKFold(n_splits = 5,shuffle=True,random_state=5440)   #set random_state to make results repeatable\n",
    "    search = BayesSearchCV(\n",
    "        estimator=RandomForestClassifier(),\n",
    "        search_spaces=hyper_params,\n",
    "        n_jobs=-1,\n",
    "        cv=cv,\n",
    "        n_iter=125,     \n",
    "        scoring=\"accuracy\",\n",
    "        verbose=0,\n",
    "        random_state=5440\n",
    "    )\n",
    "    \n",
    "    search.fit(X,Y)    \n",
    "    best_params = search.best_params_\n",
    "    print(best_params)\n",
    "    \n",
    "    #now that the best parameters are found, split the data, run on a test dataset and then predict results\n",
    "    x_train,x_test,y_train,y_test = train_test_split(X,Y,test_size=.24,random_state=5440)\n",
    "    model = RandomForestClassifier(n_estimators=best_params['n_estimators'],max_depth=best_params['max_depth']\n",
    "                                   ,criterion=best_params['criterion'],max_features=best_params)\n",
    "    model.fit(x_train,y_train)\n",
    "    pred_test = model.predict(x_test)\n",
    "    test_score = model.score(x_test,y_test)\n",
    "      \n",
    "    if graph:\n",
    "        cm = confusion_matrix(y_test,pred_test)\n",
    "        disp = ConfusionMatrixDisplay(confusion_matrix=cm,display_labels=model.classes_)\n",
    "        disp.plot(cmap='Greys')\n",
    "        plt.show()\n",
    "\n",
    "    return(test_score)\n",
    "\n",
    "def run_cross_validation_on_classification_Boost(X, Y,scoring='accuracy',iter_nbr=500,graph=False):\n",
    "    #X = predictors, Y = response, log determines if we are using linear or logistic regression\n",
    "    #first step is to use a Bayes Search algorithm to find the optimal hyperparameters\n",
    "    #define hyperparameters to search   \n",
    "    hyper_params = {\n",
    "        'n_estimators': [500, 750, 1000, 1250, 1500],\n",
    "        'max_depth': (1, 9),\n",
    "        'criterion': ['friedman_mse', 'squared_error'],\n",
    "        'max_features' : ['sqrt','log2']\n",
    "    } \n",
    "    cv = StratifiedKFold(n_splits = 5,shuffle=True,random_state=5440)   #set random_state to make results repeatable\n",
    "    search = BayesSearchCV(\n",
    "        estimator=GradientBoostingClassifier(),\n",
    "        search_spaces=hyper_params,\n",
    "        n_jobs=-1,\n",
    "        cv=cv,\n",
    "        n_iter=150,\n",
    "        scoring=\"accuracy\",\n",
    "        verbose=0,\n",
    "        random_state=5440\n",
    "    )\n",
    "    \n",
    "    search.fit(X,Y)    \n",
    "    best_params = search.best_params_\n",
    "    print(best_params)\n",
    "    \n",
    "    #now that the best parameters are found, split the data, run on a test dataset and then predict results\n",
    "    x_train,x_test,y_train,y_test = train_test_split(X,Y,test_size=.24,random_state=5440)\n",
    "    model = GradientBoostingClassifier(n_estimators=best_params['n_estimators'],max_depth=best_params['max_depth']\n",
    "                                   ,criterion=best_params['criterion'],max_features=best_params['max_features'])\n",
    "    model.fit(x_train,y_train)\n",
    "    pred_test = model.predict(x_test)\n",
    "    test_score = model.score(x_test,y_test)\n",
    "      \n",
    "    if graph:\n",
    "        cm = confusion_matrix(y_test,pred_test)\n",
    "        disp = ConfusionMatrixDisplay(confusion_matrix=cm,display_labels=model.classes_)\n",
    "        disp.plot(cmap='Greys')\n",
    "        plt.show()\n",
    "\n",
    "    return(test_score)\n",
    "\n",
    "#RDA is Regularized Discriminant Analysis (similar to how elastic-net works with Lasso and Ridge)\n",
    "def run_RDA_classification(X,Y,graph=False):\n",
    "    #X = predictors, Y = response, other numbers for the range of values\n",
    "    \n",
    "    #first step is to use a Bayes Search algorithm to find the optimal hyperparameters\n",
    "    #define hyperparameters to search\n",
    "    hyper_params = {\n",
    "        'solver' : ['lsqr','eigen'],\n",
    "        'shrinkage' : np.arange(0,1.005,.005)\n",
    "    }\n",
    "    cv = StratifiedKFold(n_splits = 5,shuffle=True,random_state=5440)   #set random_state to make results repeatable\n",
    "    search = BayesSearchCV(\n",
    "        estimator=LinearDiscriminantAnalysis(),\n",
    "        search_spaces=hyper_params,\n",
    "        n_jobs=-1,\n",
    "        cv=cv,\n",
    "        n_iter=200,\n",
    "        scoring=\"accuracy\",\n",
    "        verbose=0,\n",
    "        random_state=5440\n",
    "    )\n",
    "    \n",
    "    #find the hyperparameters on all the data and capture them for use for training and testing\n",
    "    search.fit(X,Y)    \n",
    "    best_params = search.best_params_\n",
    "    \n",
    "    #scale the X values for consistency (though may not have much effect for LDA as it would knn, PCA, gradient decent and ridge/Lasso...)\n",
    "    scaler = StandardScaler()\n",
    "    x_scaled = scaler.fit_transform(X)\n",
    "    x_train,x_test,y_train,y_test = train_test_split(x_scaled,Y,test_size=.24,random_state=5440)\n",
    "    model = LinearDiscriminantAnalysis(shrinkage=best_params['shrinkage'],solver=best_params['solver'])   \n",
    "    model.fit(x_train,y_train)\n",
    "    print(best_params)    \n",
    "     \n",
    "    #find the worth of the model  \n",
    "    pred_test = cross_val_predict(model,x_test,y_test,cv=5,n_jobs=-1)\n",
    "    pred_score = cross_val_score(model,x_test,y_test,cv=5,n_jobs=-1)\n",
    "    \n",
    "    if graph:\n",
    "        cm = confusion_matrix(y_test,pred_test)\n",
    "        disp = ConfusionMatrixDisplay(confusion_matrix=cm,display_labels=model.classes_)\n",
    "        disp.plot(cmap='Greys')\n",
    "        plt.show()\n",
    "\n",
    "    return(pred_score.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3aa682ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "#other functions\n",
    "#function to handle multi-collinearity tests\n",
    "def vif_calc(X):\n",
    "    vif_info = pd.DataFrame()\n",
    "    vif_info['VIF'] = [variance_inflation_factor(X.values, i) for i in range(X.shape[1])]\n",
    "    vif_info['Column'] = X.columns\n",
    "    vif_info.sort_values('VIF', ascending=False)\n",
    "    return(vif_info)\n",
    "\n",
    "#function to pass back AIC for linear model\n",
    "\n",
    "def aic_calc(X,Y):\n",
    "    #add constant to predictor variables\n",
    "    X = sm.add_constant(X)\n",
    "    #fit regression model\n",
    "    model = sm.OLS(Y, X).fit()\n",
    "    return(model.aic)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "105bc848",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>commodity_code</th>\n",
       "      <th>delivery_commodity_count</th>\n",
       "      <th>Diff_from_average_amt</th>\n",
       "      <th>delivery_commodity_count_avg</th>\n",
       "      <th>Diff_from_average_category</th>\n",
       "      <th>open_price</th>\n",
       "      <th>close_price</th>\n",
       "      <th>max_price</th>\n",
       "      <th>min_price</th>\n",
       "      <th>prior_day_open_price</th>\n",
       "      <th>...</th>\n",
       "      <th>recent_avg_price_diff</th>\n",
       "      <th>recent_avg_trend</th>\n",
       "      <th>prior_day_open_diff</th>\n",
       "      <th>prior_day_trend</th>\n",
       "      <th>prior_2_day_open_diff</th>\n",
       "      <th>prior_2_day_trend</th>\n",
       "      <th>prior_3_day_open_diff</th>\n",
       "      <th>prior_3_day_trend</th>\n",
       "      <th>yesterday_avg_diff</th>\n",
       "      <th>yesterday_avg_trend</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>8</td>\n",
       "      <td>2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>Average</td>\n",
       "      <td>13.680</td>\n",
       "      <td>13.6050</td>\n",
       "      <td>13.6800</td>\n",
       "      <td>13.470</td>\n",
       "      <td>13.5980</td>\n",
       "      <td>...</td>\n",
       "      <td>0.3367</td>\n",
       "      <td>Significantly Better (&gt;.10)</td>\n",
       "      <td>0.0825</td>\n",
       "      <td>Better (&gt;.05)</td>\n",
       "      <td>0.4875</td>\n",
       "      <td>Significantly Better (&gt;.10)</td>\n",
       "      <td>0.4400</td>\n",
       "      <td>Significantly Better (&gt;.10)</td>\n",
       "      <td>0.3813</td>\n",
       "      <td>Significantly Better (&gt;.10)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Average</td>\n",
       "      <td>9.315</td>\n",
       "      <td>9.3500</td>\n",
       "      <td>9.3550</td>\n",
       "      <td>9.275</td>\n",
       "      <td>9.4325</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.0617</td>\n",
       "      <td>Worse (&lt;-.05)</td>\n",
       "      <td>-0.1175</td>\n",
       "      <td>Significantly Worse (&lt;-.10)</td>\n",
       "      <td>-0.0475</td>\n",
       "      <td>Slightly Worse (&lt;-.02)</td>\n",
       "      <td>-0.0200</td>\n",
       "      <td>Slightly Worse (&lt;-.02)</td>\n",
       "      <td>0.0838</td>\n",
       "      <td>Better (&gt;.05)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>8</td>\n",
       "      <td>2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>Average</td>\n",
       "      <td>10.000</td>\n",
       "      <td>9.9575</td>\n",
       "      <td>10.0200</td>\n",
       "      <td>9.890</td>\n",
       "      <td>9.9450</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0722</td>\n",
       "      <td>Better (&gt;.05)</td>\n",
       "      <td>0.0550</td>\n",
       "      <td>Better (&gt;.05)</td>\n",
       "      <td>0.0775</td>\n",
       "      <td>Better (&gt;.05)</td>\n",
       "      <td>0.0842</td>\n",
       "      <td>Better (&gt;.05)</td>\n",
       "      <td>0.0258</td>\n",
       "      <td>Slightly Better (&gt;.02)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Average</td>\n",
       "      <td>14.950</td>\n",
       "      <td>14.8750</td>\n",
       "      <td>14.9500</td>\n",
       "      <td>14.770</td>\n",
       "      <td>14.8800</td>\n",
       "      <td>...</td>\n",
       "      <td>0.1136</td>\n",
       "      <td>Significantly Better (&gt;.10)</td>\n",
       "      <td>0.0700</td>\n",
       "      <td>Better (&gt;.05)</td>\n",
       "      <td>0.1125</td>\n",
       "      <td>Significantly Better (&gt;.10)</td>\n",
       "      <td>0.1583</td>\n",
       "      <td>Significantly Better (&gt;.10)</td>\n",
       "      <td>0.0654</td>\n",
       "      <td>Better (&gt;.05)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Average</td>\n",
       "      <td>8.910</td>\n",
       "      <td>8.9625</td>\n",
       "      <td>8.9975</td>\n",
       "      <td>8.885</td>\n",
       "      <td>8.8550</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0625</td>\n",
       "      <td>Better (&gt;.05)</td>\n",
       "      <td>0.0550</td>\n",
       "      <td>Better (&gt;.05)</td>\n",
       "      <td>0.0525</td>\n",
       "      <td>Better (&gt;.05)</td>\n",
       "      <td>0.0800</td>\n",
       "      <td>Better (&gt;.05)</td>\n",
       "      <td>0.0113</td>\n",
       "      <td>Nominal Change</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>8</td>\n",
       "      <td>3</td>\n",
       "      <td>-8.5</td>\n",
       "      <td>11.5</td>\n",
       "      <td>Average</td>\n",
       "      <td>14.500</td>\n",
       "      <td>14.4780</td>\n",
       "      <td>14.5900</td>\n",
       "      <td>14.363</td>\n",
       "      <td>14.6130</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.1983</td>\n",
       "      <td>Significantly Worse (&lt;-.10)</td>\n",
       "      <td>-0.1125</td>\n",
       "      <td>Significantly Worse (&lt;-.10)</td>\n",
       "      <td>-0.1983</td>\n",
       "      <td>Significantly Worse (&lt;-.10)</td>\n",
       "      <td>-0.2842</td>\n",
       "      <td>Significantly Worse (&lt;-.10)</td>\n",
       "      <td>-0.1288</td>\n",
       "      <td>Significantly Worse (&lt;-.10)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>8</td>\n",
       "      <td>20</td>\n",
       "      <td>8.5</td>\n",
       "      <td>11.5</td>\n",
       "      <td>Average</td>\n",
       "      <td>8.600</td>\n",
       "      <td>8.5500</td>\n",
       "      <td>8.6250</td>\n",
       "      <td>8.545</td>\n",
       "      <td>8.6700</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.1208</td>\n",
       "      <td>Significantly Worse (&lt;-.10)</td>\n",
       "      <td>-0.0700</td>\n",
       "      <td>Worse (&lt;-.05)</td>\n",
       "      <td>-0.0925</td>\n",
       "      <td>Worse (&lt;-.05)</td>\n",
       "      <td>-0.2000</td>\n",
       "      <td>Worse (&lt;-.05)</td>\n",
       "      <td>-0.0763</td>\n",
       "      <td>Worse (&lt;-.05)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>8</td>\n",
       "      <td>4</td>\n",
       "      <td>0.5</td>\n",
       "      <td>3.5</td>\n",
       "      <td>Average</td>\n",
       "      <td>12.915</td>\n",
       "      <td>12.9380</td>\n",
       "      <td>12.9500</td>\n",
       "      <td>12.765</td>\n",
       "      <td>12.8770</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0767</td>\n",
       "      <td>Better (&gt;.05)</td>\n",
       "      <td>0.0383</td>\n",
       "      <td>Slightly Better (&gt;.02)</td>\n",
       "      <td>0.0767</td>\n",
       "      <td>Better (&gt;.05)</td>\n",
       "      <td>0.1150</td>\n",
       "      <td>Better (&gt;.05)</td>\n",
       "      <td>0.0575</td>\n",
       "      <td>Better (&gt;.05)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>8</td>\n",
       "      <td>3</td>\n",
       "      <td>-0.5</td>\n",
       "      <td>3.5</td>\n",
       "      <td>Average</td>\n",
       "      <td>10.155</td>\n",
       "      <td>10.1100</td>\n",
       "      <td>10.1850</td>\n",
       "      <td>10.060</td>\n",
       "      <td>10.1440</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0217</td>\n",
       "      <td>Slightly Better (&gt;.02)</td>\n",
       "      <td>0.0108</td>\n",
       "      <td>Nominal Change</td>\n",
       "      <td>0.0217</td>\n",
       "      <td>Slightly Better (&gt;.02)</td>\n",
       "      <td>0.0325</td>\n",
       "      <td>Slightly Better (&gt;.02)</td>\n",
       "      <td>0.0163</td>\n",
       "      <td>Nominal Change</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>8</td>\n",
       "      <td>3</td>\n",
       "      <td>-6.5</td>\n",
       "      <td>9.5</td>\n",
       "      <td>Average</td>\n",
       "      <td>13.010</td>\n",
       "      <td>13.0530</td>\n",
       "      <td>13.0700</td>\n",
       "      <td>12.915</td>\n",
       "      <td>12.9150</td>\n",
       "      <td>...</td>\n",
       "      <td>0.1333</td>\n",
       "      <td>Significantly Better (&gt;.10)</td>\n",
       "      <td>0.0950</td>\n",
       "      <td>Better (&gt;.05)</td>\n",
       "      <td>0.1333</td>\n",
       "      <td>Significantly Better (&gt;.10)</td>\n",
       "      <td>0.1717</td>\n",
       "      <td>Significantly Better (&gt;.10)</td>\n",
       "      <td>0.0575</td>\n",
       "      <td>Better (&gt;.05)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>8</td>\n",
       "      <td>16</td>\n",
       "      <td>6.5</td>\n",
       "      <td>9.5</td>\n",
       "      <td>Average</td>\n",
       "      <td>10.130</td>\n",
       "      <td>10.2500</td>\n",
       "      <td>10.4500</td>\n",
       "      <td>10.125</td>\n",
       "      <td>10.1550</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.0142</td>\n",
       "      <td>Nominal Change</td>\n",
       "      <td>-0.0250</td>\n",
       "      <td>Slightly Worse (&lt;-.02)</td>\n",
       "      <td>-0.0142</td>\n",
       "      <td>Nominal Change</td>\n",
       "      <td>-0.0033</td>\n",
       "      <td>Nominal Change</td>\n",
       "      <td>0.0163</td>\n",
       "      <td>Nominal Change</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>8</td>\n",
       "      <td>16</td>\n",
       "      <td>0.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>Average</td>\n",
       "      <td>8.540</td>\n",
       "      <td>8.5300</td>\n",
       "      <td>8.5700</td>\n",
       "      <td>8.520</td>\n",
       "      <td>8.5600</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.0400</td>\n",
       "      <td>Slightly Worse (&lt;-.02)</td>\n",
       "      <td>-0.0200</td>\n",
       "      <td>Nominal Change</td>\n",
       "      <td>-0.0400</td>\n",
       "      <td>Slightly Worse (&lt;-.02)</td>\n",
       "      <td>-0.0600</td>\n",
       "      <td>Slightly Worse (&lt;-.02)</td>\n",
       "      <td>-0.0300</td>\n",
       "      <td>Slightly Worse (&lt;-.02)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>12 rows Ã— 23 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    commodity_code  delivery_commodity_count  Diff_from_average_amt  \\\n",
       "0                8                         2                    0.0   \n",
       "1                8                         1                    0.0   \n",
       "2                8                         2                    0.0   \n",
       "3                8                         1                    0.0   \n",
       "4                8                         1                    0.0   \n",
       "5                8                         3                   -8.5   \n",
       "6                8                        20                    8.5   \n",
       "7                8                         4                    0.5   \n",
       "8                8                         3                   -0.5   \n",
       "9                8                         3                   -6.5   \n",
       "10               8                        16                    6.5   \n",
       "11               8                        16                    0.0   \n",
       "\n",
       "    delivery_commodity_count_avg Diff_from_average_category  open_price  \\\n",
       "0                            2.0                    Average      13.680   \n",
       "1                            1.0                    Average       9.315   \n",
       "2                            2.0                    Average      10.000   \n",
       "3                            1.0                    Average      14.950   \n",
       "4                            1.0                    Average       8.910   \n",
       "5                           11.5                    Average      14.500   \n",
       "6                           11.5                    Average       8.600   \n",
       "7                            3.5                    Average      12.915   \n",
       "8                            3.5                    Average      10.155   \n",
       "9                            9.5                    Average      13.010   \n",
       "10                           9.5                    Average      10.130   \n",
       "11                          16.0                    Average       8.540   \n",
       "\n",
       "    close_price  max_price  min_price  prior_day_open_price  ...  \\\n",
       "0       13.6050    13.6800     13.470               13.5980  ...   \n",
       "1        9.3500     9.3550      9.275                9.4325  ...   \n",
       "2        9.9575    10.0200      9.890                9.9450  ...   \n",
       "3       14.8750    14.9500     14.770               14.8800  ...   \n",
       "4        8.9625     8.9975      8.885                8.8550  ...   \n",
       "5       14.4780    14.5900     14.363               14.6130  ...   \n",
       "6        8.5500     8.6250      8.545                8.6700  ...   \n",
       "7       12.9380    12.9500     12.765               12.8770  ...   \n",
       "8       10.1100    10.1850     10.060               10.1440  ...   \n",
       "9       13.0530    13.0700     12.915               12.9150  ...   \n",
       "10      10.2500    10.4500     10.125               10.1550  ...   \n",
       "11       8.5300     8.5700      8.520                8.5600  ...   \n",
       "\n",
       "    recent_avg_price_diff             recent_avg_trend  prior_day_open_diff  \\\n",
       "0                  0.3367  Significantly Better (>.10)               0.0825   \n",
       "1                 -0.0617                Worse (<-.05)              -0.1175   \n",
       "2                  0.0722                Better (>.05)               0.0550   \n",
       "3                  0.1136  Significantly Better (>.10)               0.0700   \n",
       "4                  0.0625                Better (>.05)               0.0550   \n",
       "5                 -0.1983  Significantly Worse (<-.10)              -0.1125   \n",
       "6                 -0.1208  Significantly Worse (<-.10)              -0.0700   \n",
       "7                  0.0767                Better (>.05)               0.0383   \n",
       "8                  0.0217       Slightly Better (>.02)               0.0108   \n",
       "9                  0.1333  Significantly Better (>.10)               0.0950   \n",
       "10                -0.0142               Nominal Change              -0.0250   \n",
       "11                -0.0400       Slightly Worse (<-.02)              -0.0200   \n",
       "\n",
       "                prior_day_trend prior_2_day_open_diff  \\\n",
       "0                 Better (>.05)                0.4875   \n",
       "1   Significantly Worse (<-.10)               -0.0475   \n",
       "2                 Better (>.05)                0.0775   \n",
       "3                 Better (>.05)                0.1125   \n",
       "4                 Better (>.05)                0.0525   \n",
       "5   Significantly Worse (<-.10)               -0.1983   \n",
       "6                 Worse (<-.05)               -0.0925   \n",
       "7        Slightly Better (>.02)                0.0767   \n",
       "8                Nominal Change                0.0217   \n",
       "9                 Better (>.05)                0.1333   \n",
       "10       Slightly Worse (<-.02)               -0.0142   \n",
       "11               Nominal Change               -0.0400   \n",
       "\n",
       "              prior_2_day_trend prior_3_day_open_diff  \\\n",
       "0   Significantly Better (>.10)                0.4400   \n",
       "1        Slightly Worse (<-.02)               -0.0200   \n",
       "2                 Better (>.05)                0.0842   \n",
       "3   Significantly Better (>.10)                0.1583   \n",
       "4                 Better (>.05)                0.0800   \n",
       "5   Significantly Worse (<-.10)               -0.2842   \n",
       "6                 Worse (<-.05)               -0.2000   \n",
       "7                 Better (>.05)                0.1150   \n",
       "8        Slightly Better (>.02)                0.0325   \n",
       "9   Significantly Better (>.10)                0.1717   \n",
       "10               Nominal Change               -0.0033   \n",
       "11       Slightly Worse (<-.02)               -0.0600   \n",
       "\n",
       "              prior_3_day_trend yesterday_avg_diff  \\\n",
       "0   Significantly Better (>.10)             0.3813   \n",
       "1        Slightly Worse (<-.02)             0.0838   \n",
       "2                 Better (>.05)             0.0258   \n",
       "3   Significantly Better (>.10)             0.0654   \n",
       "4                 Better (>.05)             0.0113   \n",
       "5   Significantly Worse (<-.10)            -0.1288   \n",
       "6                 Worse (<-.05)            -0.0763   \n",
       "7                 Better (>.05)             0.0575   \n",
       "8        Slightly Better (>.02)             0.0163   \n",
       "9   Significantly Better (>.10)             0.0575   \n",
       "10               Nominal Change             0.0163   \n",
       "11       Slightly Worse (<-.02)            -0.0300   \n",
       "\n",
       "            yesterday_avg_trend  \n",
       "0   Significantly Better (>.10)  \n",
       "1                 Better (>.05)  \n",
       "2        Slightly Better (>.02)  \n",
       "3                 Better (>.05)  \n",
       "4                Nominal Change  \n",
       "5   Significantly Worse (<-.10)  \n",
       "6                 Worse (<-.05)  \n",
       "7                 Better (>.05)  \n",
       "8                Nominal Change  \n",
       "9                 Better (>.05)  \n",
       "10               Nominal Change  \n",
       "11       Slightly Worse (<-.02)  \n",
       "\n",
       "[12 rows x 23 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#load the soybean dataset into a dataframe and confirm values\n",
    "full_start = timer()\n",
    "df_soy_raw = pd.read_csv('DataSets\\\\Soybean_Daily_Tickets_With_Price.csv')\n",
    "df_soy_raw.head(12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d57d915",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6aa5275f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>commodity_code</th>\n",
       "      <th>delivery_commodity_count</th>\n",
       "      <th>Diff_from_average_amt</th>\n",
       "      <th>delivery_commodity_count_avg</th>\n",
       "      <th>Diff_from_average_category</th>\n",
       "      <th>open_price</th>\n",
       "      <th>close_price</th>\n",
       "      <th>max_price</th>\n",
       "      <th>min_price</th>\n",
       "      <th>prior_day_open_price</th>\n",
       "      <th>...</th>\n",
       "      <th>recent_avg_price_diff</th>\n",
       "      <th>recent_avg_trend</th>\n",
       "      <th>prior_day_open_diff</th>\n",
       "      <th>prior_day_trend</th>\n",
       "      <th>prior_2_day_open_diff</th>\n",
       "      <th>prior_2_day_trend</th>\n",
       "      <th>prior_3_day_open_diff</th>\n",
       "      <th>prior_3_day_trend</th>\n",
       "      <th>yesterday_avg_diff</th>\n",
       "      <th>yesterday_avg_trend</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>Average</td>\n",
       "      <td>3.8325</td>\n",
       "      <td>3.8575</td>\n",
       "      <td>3.8675</td>\n",
       "      <td>3.7650</td>\n",
       "      <td>3.8375</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.0100</td>\n",
       "      <td>Nominal Change</td>\n",
       "      <td>-0.0050</td>\n",
       "      <td>Nominal Change</td>\n",
       "      <td>-0.0075</td>\n",
       "      <td>Nominal Change</td>\n",
       "      <td>-0.0175</td>\n",
       "      <td>Nominal Change</td>\n",
       "      <td>-0.0075</td>\n",
       "      <td>Nominal Change</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>Average</td>\n",
       "      <td>6.3900</td>\n",
       "      <td>6.4250</td>\n",
       "      <td>6.4950</td>\n",
       "      <td>6.3325</td>\n",
       "      <td>6.3100</td>\n",
       "      <td>...</td>\n",
       "      <td>0.2433</td>\n",
       "      <td>Significantly Better (&gt;.10)</td>\n",
       "      <td>0.0800</td>\n",
       "      <td>Better (&gt;.05)</td>\n",
       "      <td>0.3100</td>\n",
       "      <td>Significantly Better (&gt;.10)</td>\n",
       "      <td>0.3400</td>\n",
       "      <td>Significantly Better (&gt;.10)</td>\n",
       "      <td>0.2450</td>\n",
       "      <td>Significantly Better (&gt;.10)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>Average</td>\n",
       "      <td>6.5500</td>\n",
       "      <td>6.5525</td>\n",
       "      <td>6.6150</td>\n",
       "      <td>6.5050</td>\n",
       "      <td>6.5567</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.0133</td>\n",
       "      <td>Nominal Change</td>\n",
       "      <td>-0.0067</td>\n",
       "      <td>Nominal Change</td>\n",
       "      <td>-0.0133</td>\n",
       "      <td>Nominal Change</td>\n",
       "      <td>-0.0200</td>\n",
       "      <td>Nominal Change</td>\n",
       "      <td>-0.0100</td>\n",
       "      <td>Nominal Change</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>9</td>\n",
       "      <td>2</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>Average</td>\n",
       "      <td>3.6950</td>\n",
       "      <td>3.6950</td>\n",
       "      <td>3.7275</td>\n",
       "      <td>3.6750</td>\n",
       "      <td>3.6800</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0425</td>\n",
       "      <td>Slightly Better (&gt;.02)</td>\n",
       "      <td>0.0150</td>\n",
       "      <td>Nominal Change</td>\n",
       "      <td>0.0575</td>\n",
       "      <td>Better (&gt;.05)</td>\n",
       "      <td>0.0550</td>\n",
       "      <td>Better (&gt;.05)</td>\n",
       "      <td>0.0413</td>\n",
       "      <td>Slightly Better (&gt;.02)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>9</td>\n",
       "      <td>12</td>\n",
       "      <td>0.00</td>\n",
       "      <td>12.000000</td>\n",
       "      <td>Average</td>\n",
       "      <td>3.5975</td>\n",
       "      <td>3.5550</td>\n",
       "      <td>3.6150</td>\n",
       "      <td>3.5500</td>\n",
       "      <td>3.6200</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.0542</td>\n",
       "      <td>Worse (&lt;-.05)</td>\n",
       "      <td>-0.0225</td>\n",
       "      <td>Slightly Worse (&lt;-.02)</td>\n",
       "      <td>-0.0725</td>\n",
       "      <td>Worse (&lt;-.05)</td>\n",
       "      <td>-0.0675</td>\n",
       "      <td>Worse (&lt;-.05)</td>\n",
       "      <td>-0.0475</td>\n",
       "      <td>Slightly Worse (&lt;-.02)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>9</td>\n",
       "      <td>2</td>\n",
       "      <td>-26.50</td>\n",
       "      <td>28.500000</td>\n",
       "      <td>Below_Average</td>\n",
       "      <td>6.9350</td>\n",
       "      <td>7.0500</td>\n",
       "      <td>7.0575</td>\n",
       "      <td>6.9175</td>\n",
       "      <td>6.9000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0283</td>\n",
       "      <td>Slightly Better (&gt;.02)</td>\n",
       "      <td>0.0350</td>\n",
       "      <td>Slightly Better (&gt;.02)</td>\n",
       "      <td>0.0283</td>\n",
       "      <td>Slightly Better (&gt;.02)</td>\n",
       "      <td>0.0217</td>\n",
       "      <td>Slightly Better (&gt;.02)</td>\n",
       "      <td>-0.0100</td>\n",
       "      <td>Nominal Change</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>9</td>\n",
       "      <td>55</td>\n",
       "      <td>26.50</td>\n",
       "      <td>28.500000</td>\n",
       "      <td>Above_Average</td>\n",
       "      <td>3.5550</td>\n",
       "      <td>3.5450</td>\n",
       "      <td>3.5625</td>\n",
       "      <td>3.5250</td>\n",
       "      <td>3.5975</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.0742</td>\n",
       "      <td>Worse (&lt;-.05)</td>\n",
       "      <td>-0.0425</td>\n",
       "      <td>Slightly Worse (&lt;-.02)</td>\n",
       "      <td>-0.0650</td>\n",
       "      <td>Worse (&lt;-.05)</td>\n",
       "      <td>-0.1150</td>\n",
       "      <td>Worse (&lt;-.05)</td>\n",
       "      <td>-0.0475</td>\n",
       "      <td>Slightly Worse (&lt;-.02)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>9</td>\n",
       "      <td>10</td>\n",
       "      <td>-3.33</td>\n",
       "      <td>13.333333</td>\n",
       "      <td>Average</td>\n",
       "      <td>6.4350</td>\n",
       "      <td>6.4450</td>\n",
       "      <td>6.4575</td>\n",
       "      <td>6.3300</td>\n",
       "      <td>6.4133</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0433</td>\n",
       "      <td>Slightly Better (&gt;.02)</td>\n",
       "      <td>0.0217</td>\n",
       "      <td>Slightly Better (&gt;.02)</td>\n",
       "      <td>0.0433</td>\n",
       "      <td>Slightly Better (&gt;.02)</td>\n",
       "      <td>0.0650</td>\n",
       "      <td>Slightly Better (&gt;.02)</td>\n",
       "      <td>0.0325</td>\n",
       "      <td>Slightly Better (&gt;.02)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>9</td>\n",
       "      <td>12</td>\n",
       "      <td>-1.33</td>\n",
       "      <td>13.333333</td>\n",
       "      <td>Average</td>\n",
       "      <td>7.0500</td>\n",
       "      <td>7.0950</td>\n",
       "      <td>7.1125</td>\n",
       "      <td>7.0250</td>\n",
       "      <td>6.9350</td>\n",
       "      <td>...</td>\n",
       "      <td>0.1361</td>\n",
       "      <td>Significantly Better (&gt;.10)</td>\n",
       "      <td>0.1150</td>\n",
       "      <td>Significantly Better (&gt;.10)</td>\n",
       "      <td>0.1500</td>\n",
       "      <td>Significantly Better (&gt;.10)</td>\n",
       "      <td>0.1433</td>\n",
       "      <td>Significantly Better (&gt;.10)</td>\n",
       "      <td>0.0317</td>\n",
       "      <td>Slightly Better (&gt;.02)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>9</td>\n",
       "      <td>18</td>\n",
       "      <td>4.67</td>\n",
       "      <td>13.333333</td>\n",
       "      <td>Average</td>\n",
       "      <td>3.6425</td>\n",
       "      <td>3.6025</td>\n",
       "      <td>3.6550</td>\n",
       "      <td>3.5950</td>\n",
       "      <td>3.6475</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.0100</td>\n",
       "      <td>Nominal Change</td>\n",
       "      <td>-0.0050</td>\n",
       "      <td>Nominal Change</td>\n",
       "      <td>-0.0100</td>\n",
       "      <td>Nominal Change</td>\n",
       "      <td>-0.0150</td>\n",
       "      <td>Nominal Change</td>\n",
       "      <td>-0.0075</td>\n",
       "      <td>Nominal Change</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>9</td>\n",
       "      <td>9</td>\n",
       "      <td>-7.67</td>\n",
       "      <td>16.666667</td>\n",
       "      <td>Average</td>\n",
       "      <td>6.4675</td>\n",
       "      <td>6.5350</td>\n",
       "      <td>6.5400</td>\n",
       "      <td>6.4200</td>\n",
       "      <td>6.4350</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0542</td>\n",
       "      <td>Better (&gt;.05)</td>\n",
       "      <td>0.0325</td>\n",
       "      <td>Slightly Better (&gt;.02)</td>\n",
       "      <td>0.0542</td>\n",
       "      <td>Better (&gt;.05)</td>\n",
       "      <td>0.0758</td>\n",
       "      <td>Better (&gt;.05)</td>\n",
       "      <td>0.0325</td>\n",
       "      <td>Slightly Better (&gt;.02)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>9</td>\n",
       "      <td>9</td>\n",
       "      <td>-7.67</td>\n",
       "      <td>16.666667</td>\n",
       "      <td>Average</td>\n",
       "      <td>7.0950</td>\n",
       "      <td>7.1950</td>\n",
       "      <td>7.2200</td>\n",
       "      <td>7.0950</td>\n",
       "      <td>7.0500</td>\n",
       "      <td>...</td>\n",
       "      <td>0.1333</td>\n",
       "      <td>Significantly Better (&gt;.10)</td>\n",
       "      <td>0.0450</td>\n",
       "      <td>Slightly Better (&gt;.02)</td>\n",
       "      <td>0.1600</td>\n",
       "      <td>Significantly Better (&gt;.10)</td>\n",
       "      <td>0.1950</td>\n",
       "      <td>Significantly Better (&gt;.10)</td>\n",
       "      <td>0.1325</td>\n",
       "      <td>Significantly Better (&gt;.10)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>12 rows Ã— 23 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    commodity_code  delivery_commodity_count  Diff_from_average_amt  \\\n",
       "0                9                         1                   0.00   \n",
       "1                9                         1                   0.00   \n",
       "2                9                         1                   0.00   \n",
       "3                9                         2                   0.00   \n",
       "4                9                        12                   0.00   \n",
       "5                9                         2                 -26.50   \n",
       "6                9                        55                  26.50   \n",
       "7                9                        10                  -3.33   \n",
       "8                9                        12                  -1.33   \n",
       "9                9                        18                   4.67   \n",
       "10               9                         9                  -7.67   \n",
       "11               9                         9                  -7.67   \n",
       "\n",
       "    delivery_commodity_count_avg Diff_from_average_category  open_price  \\\n",
       "0                       1.000000                    Average      3.8325   \n",
       "1                       1.000000                    Average      6.3900   \n",
       "2                       1.000000                    Average      6.5500   \n",
       "3                       2.000000                    Average      3.6950   \n",
       "4                      12.000000                    Average      3.5975   \n",
       "5                      28.500000              Below_Average      6.9350   \n",
       "6                      28.500000              Above_Average      3.5550   \n",
       "7                      13.333333                    Average      6.4350   \n",
       "8                      13.333333                    Average      7.0500   \n",
       "9                      13.333333                    Average      3.6425   \n",
       "10                     16.666667                    Average      6.4675   \n",
       "11                     16.666667                    Average      7.0950   \n",
       "\n",
       "    close_price  max_price  min_price  prior_day_open_price  ...  \\\n",
       "0        3.8575     3.8675     3.7650                3.8375  ...   \n",
       "1        6.4250     6.4950     6.3325                6.3100  ...   \n",
       "2        6.5525     6.6150     6.5050                6.5567  ...   \n",
       "3        3.6950     3.7275     3.6750                3.6800  ...   \n",
       "4        3.5550     3.6150     3.5500                3.6200  ...   \n",
       "5        7.0500     7.0575     6.9175                6.9000  ...   \n",
       "6        3.5450     3.5625     3.5250                3.5975  ...   \n",
       "7        6.4450     6.4575     6.3300                6.4133  ...   \n",
       "8        7.0950     7.1125     7.0250                6.9350  ...   \n",
       "9        3.6025     3.6550     3.5950                3.6475  ...   \n",
       "10       6.5350     6.5400     6.4200                6.4350  ...   \n",
       "11       7.1950     7.2200     7.0950                7.0500  ...   \n",
       "\n",
       "    recent_avg_price_diff             recent_avg_trend  prior_day_open_diff  \\\n",
       "0                 -0.0100               Nominal Change              -0.0050   \n",
       "1                  0.2433  Significantly Better (>.10)               0.0800   \n",
       "2                 -0.0133               Nominal Change              -0.0067   \n",
       "3                  0.0425       Slightly Better (>.02)               0.0150   \n",
       "4                 -0.0542                Worse (<-.05)              -0.0225   \n",
       "5                  0.0283       Slightly Better (>.02)               0.0350   \n",
       "6                 -0.0742                Worse (<-.05)              -0.0425   \n",
       "7                  0.0433       Slightly Better (>.02)               0.0217   \n",
       "8                  0.1361  Significantly Better (>.10)               0.1150   \n",
       "9                 -0.0100               Nominal Change              -0.0050   \n",
       "10                 0.0542                Better (>.05)               0.0325   \n",
       "11                 0.1333  Significantly Better (>.10)               0.0450   \n",
       "\n",
       "                prior_day_trend prior_2_day_open_diff  \\\n",
       "0                Nominal Change               -0.0075   \n",
       "1                 Better (>.05)                0.3100   \n",
       "2                Nominal Change               -0.0133   \n",
       "3                Nominal Change                0.0575   \n",
       "4        Slightly Worse (<-.02)               -0.0725   \n",
       "5        Slightly Better (>.02)                0.0283   \n",
       "6        Slightly Worse (<-.02)               -0.0650   \n",
       "7        Slightly Better (>.02)                0.0433   \n",
       "8   Significantly Better (>.10)                0.1500   \n",
       "9                Nominal Change               -0.0100   \n",
       "10       Slightly Better (>.02)                0.0542   \n",
       "11       Slightly Better (>.02)                0.1600   \n",
       "\n",
       "              prior_2_day_trend prior_3_day_open_diff  \\\n",
       "0                Nominal Change               -0.0175   \n",
       "1   Significantly Better (>.10)                0.3400   \n",
       "2                Nominal Change               -0.0200   \n",
       "3                 Better (>.05)                0.0550   \n",
       "4                 Worse (<-.05)               -0.0675   \n",
       "5        Slightly Better (>.02)                0.0217   \n",
       "6                 Worse (<-.05)               -0.1150   \n",
       "7        Slightly Better (>.02)                0.0650   \n",
       "8   Significantly Better (>.10)                0.1433   \n",
       "9                Nominal Change               -0.0150   \n",
       "10                Better (>.05)                0.0758   \n",
       "11  Significantly Better (>.10)                0.1950   \n",
       "\n",
       "              prior_3_day_trend yesterday_avg_diff  \\\n",
       "0                Nominal Change            -0.0075   \n",
       "1   Significantly Better (>.10)             0.2450   \n",
       "2                Nominal Change            -0.0100   \n",
       "3                 Better (>.05)             0.0413   \n",
       "4                 Worse (<-.05)            -0.0475   \n",
       "5        Slightly Better (>.02)            -0.0100   \n",
       "6                 Worse (<-.05)            -0.0475   \n",
       "7        Slightly Better (>.02)             0.0325   \n",
       "8   Significantly Better (>.10)             0.0317   \n",
       "9                Nominal Change            -0.0075   \n",
       "10                Better (>.05)             0.0325   \n",
       "11  Significantly Better (>.10)             0.1325   \n",
       "\n",
       "            yesterday_avg_trend  \n",
       "0                Nominal Change  \n",
       "1   Significantly Better (>.10)  \n",
       "2                Nominal Change  \n",
       "3        Slightly Better (>.02)  \n",
       "4        Slightly Worse (<-.02)  \n",
       "5                Nominal Change  \n",
       "6        Slightly Worse (<-.02)  \n",
       "7        Slightly Better (>.02)  \n",
       "8        Slightly Better (>.02)  \n",
       "9                Nominal Change  \n",
       "10       Slightly Better (>.02)  \n",
       "11  Significantly Better (>.10)  \n",
       "\n",
       "[12 rows x 23 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Load the corn dataset into a dataframe and confirm the values\n",
    "df_corn_raw = pd.read_csv('DataSets\\\\Corn_Daily_Tickets_With_Price.csv')\n",
    "df_corn_raw.head(12)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35d44503",
   "metadata": {},
   "source": [
    "Response variables are Diff_from_average_amt (regression) and Diff_from_average_category (classification)\n",
    "\n",
    "Prep both corn and soybean datasets and create both a \"full\" and \"partial\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "159d79d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_soy = df_soy_raw.copy()\n",
    "df_corn = df_corn_raw.copy()\n",
    "\n",
    "#drop fields not needed for analysis\n",
    "df_soy = df_soy.drop(['commodity_code','delivery_commodity_count','delivery_commodity_count_avg'],axis=1)\n",
    "df_corn = df_corn.drop(['commodity_code','delivery_commodity_count','delivery_commodity_count_avg'],axis=1)\n",
    "\n",
    "#create full data sets for each type of analysis\n",
    "ys_reg = df_soy['Diff_from_average_amt']\n",
    "ys_class = df_soy['Diff_from_average_category']\n",
    "xs_full = df_soy.drop(['Diff_from_average_category','Diff_from_average_amt'],axis=1)\n",
    "xs_full = pd.get_dummies(xs_full,drop_first = True) #make dummies for categorical values\n",
    "\n",
    "yc_reg = df_corn['Diff_from_average_amt']\n",
    "yc_class = df_corn['Diff_from_average_category']\n",
    "xc_full = df_corn.drop(['Diff_from_average_category','Diff_from_average_amt'],axis=1)\n",
    "xc_full = pd.get_dummies(xc_full,drop_first = True) #make dummies for categorical values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5bfc3ded",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>VIF</th>\n",
       "      <th>Column</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2.983324e+09</td>\n",
       "      <td>open_price</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2.360417e+04</td>\n",
       "      <td>close_price</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3.146889e+04</td>\n",
       "      <td>max_price</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3.084581e+04</td>\n",
       "      <td>min_price</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3.098498e+09</td>\n",
       "      <td>prior_day_open_price</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>3.842165e+09</td>\n",
       "      <td>prior_2_day_open_price</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>2.892944e+09</td>\n",
       "      <td>prior_3_day_open_price</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>3.258452e+09</td>\n",
       "      <td>recent_avg_price</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>4.398538e+07</td>\n",
       "      <td>recent_avg_price_diff</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>1.570947e+07</td>\n",
       "      <td>prior_day_open_diff</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>1.691602e+07</td>\n",
       "      <td>prior_2_day_open_diff</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>2.506571e+07</td>\n",
       "      <td>prior_3_day_open_diff</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>1.645521e+07</td>\n",
       "      <td>yesterday_avg_diff</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>2.721075e+00</td>\n",
       "      <td>recent_avg_trend_Nominal Change</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>3.991322e+00</td>\n",
       "      <td>recent_avg_trend_Significantly Better (&gt;.10)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>9.570433e+00</td>\n",
       "      <td>recent_avg_trend_Significantly Worse (&lt;-.10)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>1.811295e+00</td>\n",
       "      <td>recent_avg_trend_Slightly Better (&gt;.02)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>2.536460e+00</td>\n",
       "      <td>recent_avg_trend_Slightly Worse (&lt;-.02)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>3.791533e+00</td>\n",
       "      <td>recent_avg_trend_Worse (&lt;-.05)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>3.774658e+00</td>\n",
       "      <td>prior_day_trend_Nominal Change</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>3.134915e+00</td>\n",
       "      <td>prior_day_trend_Significantly Better (&gt;.10)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>7.982139e+00</td>\n",
       "      <td>prior_day_trend_Significantly Worse (&lt;-.10)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>2.055960e+00</td>\n",
       "      <td>prior_day_trend_Slightly Better (&gt;.02)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>2.780944e+00</td>\n",
       "      <td>prior_day_trend_Slightly Worse (&lt;-.02)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>4.056209e+00</td>\n",
       "      <td>prior_day_trend_Worse (&lt;-.05)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>2.759399e+00</td>\n",
       "      <td>yesterday_avg_trend_Nominal Change</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>3.061358e+00</td>\n",
       "      <td>yesterday_avg_trend_Significantly Better (&gt;.10)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>5.430370e+00</td>\n",
       "      <td>yesterday_avg_trend_Significantly Worse (&lt;-.10)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>1.888951e+00</td>\n",
       "      <td>yesterday_avg_trend_Slightly Better (&gt;.02)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>2.290573e+00</td>\n",
       "      <td>yesterday_avg_trend_Slightly Worse (&lt;-.02)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>2.861313e+00</td>\n",
       "      <td>yesterday_avg_trend_Worse (&lt;-.05)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             VIF                                           Column\n",
       "0   2.983324e+09                                       open_price\n",
       "1   2.360417e+04                                      close_price\n",
       "2   3.146889e+04                                        max_price\n",
       "3   3.084581e+04                                        min_price\n",
       "4   3.098498e+09                             prior_day_open_price\n",
       "5   3.842165e+09                           prior_2_day_open_price\n",
       "6   2.892944e+09                           prior_3_day_open_price\n",
       "7   3.258452e+09                                 recent_avg_price\n",
       "8   4.398538e+07                            recent_avg_price_diff\n",
       "9   1.570947e+07                              prior_day_open_diff\n",
       "10  1.691602e+07                            prior_2_day_open_diff\n",
       "11  2.506571e+07                            prior_3_day_open_diff\n",
       "12  1.645521e+07                               yesterday_avg_diff\n",
       "13  2.721075e+00                  recent_avg_trend_Nominal Change\n",
       "14  3.991322e+00     recent_avg_trend_Significantly Better (>.10)\n",
       "15  9.570433e+00     recent_avg_trend_Significantly Worse (<-.10)\n",
       "16  1.811295e+00          recent_avg_trend_Slightly Better (>.02)\n",
       "17  2.536460e+00          recent_avg_trend_Slightly Worse (<-.02)\n",
       "18  3.791533e+00                   recent_avg_trend_Worse (<-.05)\n",
       "19  3.774658e+00                   prior_day_trend_Nominal Change\n",
       "20  3.134915e+00      prior_day_trend_Significantly Better (>.10)\n",
       "21  7.982139e+00      prior_day_trend_Significantly Worse (<-.10)\n",
       "22  2.055960e+00           prior_day_trend_Slightly Better (>.02)\n",
       "23  2.780944e+00           prior_day_trend_Slightly Worse (<-.02)\n",
       "24  4.056209e+00                    prior_day_trend_Worse (<-.05)\n",
       "25  2.759399e+00               yesterday_avg_trend_Nominal Change\n",
       "26  3.061358e+00  yesterday_avg_trend_Significantly Better (>.10)\n",
       "27  5.430370e+00  yesterday_avg_trend_Significantly Worse (<-.10)\n",
       "28  1.888951e+00       yesterday_avg_trend_Slightly Better (>.02)\n",
       "29  2.290573e+00       yesterday_avg_trend_Slightly Worse (<-.02)\n",
       "30  2.861313e+00                yesterday_avg_trend_Worse (<-.05)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#take a look  at the vif calcuations for soybeans\n",
    "vif_calc(xs_full)\n",
    "#remove infinite values\n",
    "xs_part = xs_full.drop(['prior_2_day_trend_Nominal Change','prior_2_day_trend_Significantly Better (>.10)','prior_2_day_trend_Significantly Worse (<-.10)','prior_2_day_trend_Slightly Better (>.02)','prior_2_day_trend_Slightly Worse (<-.02)','prior_2_day_trend_Worse (<-.05)','prior_3_day_trend_Nominal Change','prior_3_day_trend_Significantly Better (>.10)','prior_3_day_trend_Significantly Worse (<-.10)','prior_3_day_trend_Slightly Better (>.02)','prior_3_day_trend_Slightly Worse (<-.02)','prior_3_day_trend_Worse (<-.05)'],axis=1)\n",
    "vif_calc(xs_part)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec90d743",
   "metadata": {},
   "source": [
    "This is quite interesting in that there are either numbers under 10 or numbers over 16 million.  Sine I know the recent price is the average of the prior day open prices, I will remove the 6 \"prior\" fields to see how it shakes out."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7601d407",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[22229.73698809 22228.17234377 22228.17034121 22228.171763  ]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>VIF</th>\n",
       "      <th>Column</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>12.463547</td>\n",
       "      <td>recent_avg_price</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>7.370476</td>\n",
       "      <td>recent_avg_price_diff</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>7.529689</td>\n",
       "      <td>yesterday_avg_diff</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2.707760</td>\n",
       "      <td>recent_avg_trend_Nominal Change</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3.958342</td>\n",
       "      <td>recent_avg_trend_Significantly Better (&gt;.10)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>9.435674</td>\n",
       "      <td>recent_avg_trend_Significantly Worse (&lt;-.10)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1.803613</td>\n",
       "      <td>recent_avg_trend_Slightly Better (&gt;.02)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>2.519132</td>\n",
       "      <td>recent_avg_trend_Slightly Worse (&lt;-.02)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>3.752933</td>\n",
       "      <td>recent_avg_trend_Worse (&lt;-.05)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>3.742457</td>\n",
       "      <td>prior_day_trend_Nominal Change</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>3.092704</td>\n",
       "      <td>prior_day_trend_Significantly Better (&gt;.10)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>7.919284</td>\n",
       "      <td>prior_day_trend_Significantly Worse (&lt;-.10)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>2.030507</td>\n",
       "      <td>prior_day_trend_Slightly Better (&gt;.02)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>2.755010</td>\n",
       "      <td>prior_day_trend_Slightly Worse (&lt;-.02)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>4.005623</td>\n",
       "      <td>prior_day_trend_Worse (&lt;-.05)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>2.677610</td>\n",
       "      <td>yesterday_avg_trend_Nominal Change</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>3.031973</td>\n",
       "      <td>yesterday_avg_trend_Significantly Better (&gt;.10)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>5.194811</td>\n",
       "      <td>yesterday_avg_trend_Significantly Worse (&lt;-.10)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>1.878629</td>\n",
       "      <td>yesterday_avg_trend_Slightly Better (&gt;.02)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>2.157879</td>\n",
       "      <td>yesterday_avg_trend_Slightly Worse (&lt;-.02)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>2.680296</td>\n",
       "      <td>yesterday_avg_trend_Worse (&lt;-.05)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          VIF                                           Column\n",
       "0   12.463547                                 recent_avg_price\n",
       "1    7.370476                            recent_avg_price_diff\n",
       "2    7.529689                               yesterday_avg_diff\n",
       "3    2.707760                  recent_avg_trend_Nominal Change\n",
       "4    3.958342     recent_avg_trend_Significantly Better (>.10)\n",
       "5    9.435674     recent_avg_trend_Significantly Worse (<-.10)\n",
       "6    1.803613          recent_avg_trend_Slightly Better (>.02)\n",
       "7    2.519132          recent_avg_trend_Slightly Worse (<-.02)\n",
       "8    3.752933                   recent_avg_trend_Worse (<-.05)\n",
       "9    3.742457                   prior_day_trend_Nominal Change\n",
       "10   3.092704      prior_day_trend_Significantly Better (>.10)\n",
       "11   7.919284      prior_day_trend_Significantly Worse (<-.10)\n",
       "12   2.030507           prior_day_trend_Slightly Better (>.02)\n",
       "13   2.755010           prior_day_trend_Slightly Worse (<-.02)\n",
       "14   4.005623                    prior_day_trend_Worse (<-.05)\n",
       "15   2.677610               yesterday_avg_trend_Nominal Change\n",
       "16   3.031973  yesterday_avg_trend_Significantly Better (>.10)\n",
       "17   5.194811  yesterday_avg_trend_Significantly Worse (<-.10)\n",
       "18   1.878629       yesterday_avg_trend_Slightly Better (>.02)\n",
       "19   2.157879       yesterday_avg_trend_Slightly Worse (<-.02)\n",
       "20   2.680296                yesterday_avg_trend_Worse (<-.05)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#remove\n",
    "xs_part = xs_part.drop(['prior_day_open_price','prior_2_day_open_price','prior_3_day_open_price','prior_day_open_diff','prior_2_day_open_diff','prior_3_day_open_diff'],axis=1)\n",
    "vif_calc(xs_part)\n",
    "\n",
    "# take a look at correlation to see which ones should go next\n",
    "#run a correlation test on the high ones to see what make sense to keep\n",
    "xs_temp = df_soy[['Diff_from_average_amt','open_price','close_price','max_price','min_price','recent_avg_price','recent_avg_price_diff']]\n",
    "corr = xs_temp.corr()\n",
    "corr.style.background_gradient(cmap='coolwarm')\n",
    "\n",
    "#according to the corrlation, I am going to keep open price and remove close/max/min and the recent average (in favor of diff)\n",
    "xs_part = xs_part.drop(['max_price','close_price','min_price'],axis=1)\n",
    "vif_calc(xs_part)\n",
    "\n",
    "#run a correlation test on the high ones to see what make sense to keep\n",
    "xs_temp = df_soy[['Diff_from_average_amt','open_price','recent_avg_price','recent_avg_price_diff']]\n",
    "corr = xs_temp.corr()\n",
    "corr.style.background_gradient(cmap='coolwarm')\n",
    "\n",
    "#do aic checks on the one I should remove\n",
    "aic_val =np.empty(4)\n",
    "aic_val[0] = aic_calc(xs_part,ys_reg)\n",
    "temp_x = xs_part.drop(['open_price'],axis=1)\n",
    "aic_val[1] = aic_calc(temp_x,ys_reg)\n",
    "temp_x = xs_part.drop(['recent_avg_price'],axis=1)\n",
    "aic_val[2] = aic_calc(temp_x,ys_reg)\n",
    "temp_x = xs_part.drop(['recent_avg_price_diff'],axis=1)\n",
    "aic_val[3] = aic_calc(temp_x,ys_reg)\n",
    "print(aic_val)\n",
    "\n",
    "#looks like enough of the open price is found in the average price for the prior 3 days.  Vif is still above 10 but not too bad.\n",
    "xs_part = xs_part.drop(['open_price'],axis=1)\n",
    "vif_calc(xs_part)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1dacd805",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[23908.39418097 23907.23657573 23907.22117426 23908.98467761]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>VIF</th>\n",
       "      <th>Column</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10.133898</td>\n",
       "      <td>close_price</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>8.785319</td>\n",
       "      <td>recent_avg_price_diff</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>8.324484</td>\n",
       "      <td>yesterday_avg_diff</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>6.347819</td>\n",
       "      <td>recent_avg_trend_Nominal Change</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3.117076</td>\n",
       "      <td>recent_avg_trend_Significantly Better (&gt;.10)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>8.707889</td>\n",
       "      <td>recent_avg_trend_Significantly Worse (&lt;-.10)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>2.991629</td>\n",
       "      <td>recent_avg_trend_Slightly Better (&gt;.02)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>5.504175</td>\n",
       "      <td>recent_avg_trend_Slightly Worse (&lt;-.02)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>6.772942</td>\n",
       "      <td>recent_avg_trend_Worse (&lt;-.05)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>7.594945</td>\n",
       "      <td>prior_day_trend_Nominal Change</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>2.535718</td>\n",
       "      <td>prior_day_trend_Significantly Better (&gt;.10)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>6.423754</td>\n",
       "      <td>prior_day_trend_Significantly Worse (&lt;-.10)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>2.655992</td>\n",
       "      <td>prior_day_trend_Slightly Better (&gt;.02)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>5.591363</td>\n",
       "      <td>prior_day_trend_Slightly Worse (&lt;-.02)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>4.736788</td>\n",
       "      <td>prior_day_trend_Worse (&lt;-.05)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>5.177147</td>\n",
       "      <td>yesterday_avg_trend_Nominal Change</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>2.408250</td>\n",
       "      <td>yesterday_avg_trend_Significantly Better (&gt;.10)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>5.169185</td>\n",
       "      <td>yesterday_avg_trend_Significantly Worse (&lt;-.10)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>2.476920</td>\n",
       "      <td>yesterday_avg_trend_Slightly Better (&gt;.02)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>4.058170</td>\n",
       "      <td>yesterday_avg_trend_Slightly Worse (&lt;-.02)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>3.796032</td>\n",
       "      <td>yesterday_avg_trend_Worse (&lt;-.05)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          VIF                                           Column\n",
       "0   10.133898                                      close_price\n",
       "1    8.785319                            recent_avg_price_diff\n",
       "2    8.324484                               yesterday_avg_diff\n",
       "3    6.347819                  recent_avg_trend_Nominal Change\n",
       "4    3.117076     recent_avg_trend_Significantly Better (>.10)\n",
       "5    8.707889     recent_avg_trend_Significantly Worse (<-.10)\n",
       "6    2.991629          recent_avg_trend_Slightly Better (>.02)\n",
       "7    5.504175          recent_avg_trend_Slightly Worse (<-.02)\n",
       "8    6.772942                   recent_avg_trend_Worse (<-.05)\n",
       "9    7.594945                   prior_day_trend_Nominal Change\n",
       "10   2.535718      prior_day_trend_Significantly Better (>.10)\n",
       "11   6.423754      prior_day_trend_Significantly Worse (<-.10)\n",
       "12   2.655992           prior_day_trend_Slightly Better (>.02)\n",
       "13   5.591363           prior_day_trend_Slightly Worse (<-.02)\n",
       "14   4.736788                    prior_day_trend_Worse (<-.05)\n",
       "15   5.177147               yesterday_avg_trend_Nominal Change\n",
       "16   2.408250  yesterday_avg_trend_Significantly Better (>.10)\n",
       "17   5.169185  yesterday_avg_trend_Significantly Worse (<-.10)\n",
       "18   2.476920       yesterday_avg_trend_Slightly Better (>.02)\n",
       "19   4.058170       yesterday_avg_trend_Slightly Worse (<-.02)\n",
       "20   3.796032                yesterday_avg_trend_Worse (<-.05)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#now do the same for corn\n",
    "\n",
    "vif_calc(xc_full)\n",
    "#remove infinite values\n",
    "\n",
    "xc_part = xc_full.drop(['prior_2_day_trend_Nominal Change','prior_2_day_trend_Significantly Better (>.10)','prior_2_day_trend_Significantly Worse (<-.10)','prior_2_day_trend_Slightly Better (>.02)','prior_2_day_trend_Slightly Worse (<-.02)','prior_2_day_trend_Worse (<-.05)','prior_3_day_trend_Nominal Change','prior_3_day_trend_Significantly Better (>.10)','prior_3_day_trend_Significantly Worse (<-.10)','prior_3_day_trend_Slightly Better (>.02)','prior_3_day_trend_Slightly Worse (<-.02)','prior_3_day_trend_Worse (<-.05)'],axis=1)\n",
    "vif_calc(xc_part)\n",
    "#remove since they are a part of recent\n",
    "xc_part = xc_part.drop(['prior_day_open_price','prior_2_day_open_price','prior_3_day_open_price','prior_day_open_diff','prior_2_day_open_diff','prior_3_day_open_diff'],axis=1)\n",
    "vif_calc(xc_part)\n",
    "\n",
    "xc_temp = df_corn[['Diff_from_average_amt','open_price','close_price','max_price','min_price','recent_avg_price','recent_avg_price_diff']]\n",
    "corr = xc_temp.corr()\n",
    "corr.style.background_gradient(cmap='coolwarm')\n",
    "\n",
    "#according to the corrlation, close_price is more related to corn than open\n",
    "xc_part = xc_part.drop(['max_price','open_price','min_price'],axis=1)\n",
    "vif_calc(xc_part)\n",
    "\n",
    "#do aic checks on the one I should remove\n",
    "aic_val =np.empty(4)\n",
    "aic_val[0] = aic_calc(xc_part,yc_reg)\n",
    "temp_x = xc_part.drop(['close_price'],axis=1)\n",
    "aic_val[1] = aic_calc(temp_x,yc_reg)\n",
    "temp_x = xc_part.drop(['recent_avg_price'],axis=1)\n",
    "aic_val[2] = aic_calc(temp_x,yc_reg)\n",
    "temp_x = xc_part.drop(['recent_avg_price_diff'],axis=1)\n",
    "aic_val[3] = aic_calc(temp_x,yc_reg)\n",
    "print(aic_val)\n",
    "\n",
    "#AIC tells us that dropping recent_avg_price produces the best results.  Surprised.... Highest vif is around 10 so we are good.\n",
    "xc_part = xc_part.drop(['recent_avg_price'],axis=1)\n",
    "vif_calc(xc_part)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "589e8254",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OrderedDict([('fit_intercept', False), ('positive', False)])\n",
      "Linear Model on Data Subset Complete in 4.1002301 seconds\n",
      "OrderedDict([('alpha', 1.0), ('fit_intercept', False), ('l1_ratio', 0.3)])\n",
      "Enet Regression Model on Full Dataset Complete in 560.4871969 seconds\n",
      "100.0\n",
      "Ridge Regression Model on Data Subset Complete in 4.467145500000015 seconds\n",
      "OrderedDict([('criterion', 'squared_error'), ('max_depth', 4), ('n_estimators', 200)])\n",
      "Random Forest Model on Data Subset Complete in 1017.887733 seconds\n",
      "OrderedDict([('criterion', 'friedman_mse'), ('loss', 'squared_error'), ('max_depth', 1), ('max_features', 'sqrt'), ('n_estimators', 500)])\n",
      "Boosted Trees Model on Full Dataset Complete in 571.5379677999999 seconds\n",
      "OrderedDict([('criterion', 'squared_error'), ('loss', 'squared_error'), ('max_depth', 1), ('max_features', 'log2'), ('n_estimators', 500)])\n",
      "Boosted Trees Model on Data Subset Complete in 553.8900981000002 seconds\n"
     ]
    }
   ],
   "source": [
    "#Soybeans Regression\n",
    "# With the regression functions defined, run the regressions and capture the RMSE and R-squared\n",
    "start = timer()\n",
    "linear_rmse,linear_r2 = run_linear(xs_part,ys_reg)\n",
    "end = timer()\n",
    "print(f'Linear Model on Data Subset Complete in {end-start} seconds')\n",
    "\n",
    "start = timer()      \n",
    "enet_full_rmse,enet_full_r2 = run_enet_regression(xs_full,ys_reg)\n",
    "end = timer()\n",
    "print(f'Enet Regression Model on Full Dataset Complete in {end-start} seconds')\n",
    "\n",
    "start = timer()  \n",
    "ridge_part_rmse,ridge_part_r2 = run_ridge_regression(xs_part,ys_reg)\n",
    "end = timer()\n",
    "print(f'Ridge Regression Model on Data Subset Complete in {end-start} seconds')\n",
    "\n",
    "start = timer()  \n",
    "rfr_rmse,rfr_r2 = run_cross_validation_on_regression_RF(xs_part,ys_reg)\n",
    "end = timer()\n",
    "print(f'Random Forest Model on Data Subset Complete in {end-start} seconds')\n",
    "\n",
    "start = timer()  \n",
    "boost_rmse,boost_r2 = run_cross_validation_on_regression_Boost(xs_full,ys_reg)\n",
    "end = timer()\n",
    "print(f'Boosted Trees Model on Full Dataset Complete in {end-start} seconds')\n",
    "\n",
    "start = timer()  \n",
    "boost_part_rmse,boost_part_r2 = run_cross_validation_on_regression_Boost(xs_part,ys_reg)\n",
    "end = timer()\n",
    "print(f'Boosted Trees Model on Data Subset Complete in {end-start} seconds')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "7ee18fc1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model_Name</th>\n",
       "      <th>Data_Used</th>\n",
       "      <th>RMSE</th>\n",
       "      <th>R_Squared</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Boosted Trees Run 1</td>\n",
       "      <td>Full</td>\n",
       "      <td>55.976456</td>\n",
       "      <td>0.171250</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Boosted Trees Run 2</td>\n",
       "      <td>Subset</td>\n",
       "      <td>56.718226</td>\n",
       "      <td>0.149140</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Random Forest Run 1</td>\n",
       "      <td>Subset</td>\n",
       "      <td>56.919788</td>\n",
       "      <td>0.143082</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Ridge Run 1</td>\n",
       "      <td>Subset</td>\n",
       "      <td>58.592939</td>\n",
       "      <td>0.091963</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Linear Run 1</td>\n",
       "      <td>Subset</td>\n",
       "      <td>59.088801</td>\n",
       "      <td>0.076529</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ENet Run 1</td>\n",
       "      <td>Full</td>\n",
       "      <td>59.164919</td>\n",
       "      <td>0.074148</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            Model_Name Data_Used       RMSE  R_Squared\n",
       "4  Boosted Trees Run 1      Full  55.976456   0.171250\n",
       "5  Boosted Trees Run 2    Subset  56.718226   0.149140\n",
       "3  Random Forest Run 1    Subset  56.919788   0.143082\n",
       "2          Ridge Run 1    Subset  58.592939   0.091963\n",
       "0         Linear Run 1    Subset  59.088801   0.076529\n",
       "1           ENet Run 1      Full  59.164919   0.074148"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Soybeans Regression results\n",
    "result_ds_list  = [['Linear Run 1','Subset',linear_rmse,linear_r2]\n",
    "                  ,['ENet Run 1','Full',enet_full_rmse,enet_full_r2]\n",
    "                  ,['Ridge Run 1','Subset',ridge_part_rmse,ridge_part_r2]\n",
    "                  ,['Random Forest Run 1','Subset',rfr_rmse,rfr_r2]\n",
    "                  ,['Boosted Trees Run 1','Full',boost_rmse,boost_r2]\n",
    "                  ,['Boosted Trees Run 2','Subset',boost_part_rmse,boost_part_r2]]\n",
    "results_delivery_count = pd.DataFrame(result_ds_list,columns=['Model','Dataset','RMSE','R^2'])\n",
    "results_delivery_count.sort_values(['RMSE','R_Squared'],ascending=[True,False])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1835df59",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OrderedDict([('fit_intercept', False), ('solver', 'newton-cg')])\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Model on Data Subset Complete in 80.36375789999965 seconds\n"
     ]
    }
   ],
   "source": [
    "#Soybeans Classfication\n",
    "start = timer()\n",
    "log_accuracy_part = run_logistic(xs_part,ys_class,graph=True)\n",
    "end = timer()\n",
    "print(f'Logistic Model on Data Subset Complete in {end-start} seconds')\n",
    "\n",
    "start = timer()\n",
    "rda_accuracy_full = run_RDA_classification(xs_full,ys_class,graph=True)\n",
    "end = timer()\n",
    "print(f'RDA Model on Full Data Complete in {end-start} seconds')\n",
    "\n",
    "start = timer()\n",
    "rda_accuracy_part = run_RDA_classification(xs_part,ys_class,graph=True)\n",
    "end = timer()\n",
    "print(f'RDA Model on Data Subset Complete in {end-start} seconds')\n",
    "\n",
    "start = timer()\n",
    "rf_accuracy_part = run_cross_validation_on_classification_RF(xs_part,ys_class,graph=True)\n",
    "end = timer()\n",
    "print(f'Random Forest Model on Data Subset Complete in {end-start} seconds')\n",
    "\n",
    "start = timer()\n",
    "boost_accuracy_full = run_cross_validation_on_classification_Boost(xs_full,ys_class,graph=True)\n",
    "end = timer()\n",
    "print(f'Boosted Trees Model on Full Dataset Complete in {end-start} seconds')\n",
    "\n",
    "start = timer()\n",
    "boost_accuracy_part = run_cross_validation_on_classification_Boost(xs_part,ys_class,graph=True)\n",
    "end = timer()\n",
    "print(f'Boosted Trees Model on Data Subset Complete in {end-start} seconds')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3793e22",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Soybeans Classification Results\n",
    "#create a data frame of the results for analysis\n",
    "result_aa_list  = [['Logistic Run 1','Partial',log_accuracy_part]\n",
    "                  ,['RDA Run 1','Full',rda_accuracy_full]\n",
    "                  ,['RDA Run 2','Partial',rda_accuracy_part]\n",
    "                  ,['Random Forest Run 1','Partial',rf_accuracy_part]\n",
    "                  ,['Boosted Trees Run 1','Full',boost_accuracy_full]\n",
    "                  ,['Boosted Trees Run 2','Partial',boost_accuracy_part]]\n",
    "results_above_average = pd.DataFrame(result_aa_list,columns=['Model','Dataset','Accuracy'])\n",
    "results_above_average.sort_values(['Accuracy'],ascending=[False])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "287e06d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Corn Regression\n",
    "# With the regression functions defined, run the regressions and capture the RMSE and R-squared\n",
    "start = timer()\n",
    "linear_rmse,linear_r2 = run_linear(xc_part,yc_reg)\n",
    "end = timer()\n",
    "print(f'Linear Model on Data Subset Complete in {end-start} seconds')\n",
    "\n",
    "start = timer()      \n",
    "enet_full_rmse,enet_full_r2 = run_enet_regression(xc_full,yc_reg)\n",
    "end = timer()\n",
    "print(f'Enet Regression Model on Full Dataset Complete in {end-start} seconds')\n",
    "\n",
    "start = timer()  \n",
    "ridge_part_rmse,ridge_part_r2 = run_ridge_regression(xc_part,yc_reg)\n",
    "end = timer()\n",
    "print(f'Ridge Regression Model on Data Subset Complete in {end-start} seconds')\n",
    "\n",
    "start = timer()  \n",
    "rfr_rmse,rfr_r2 = run_cross_validation_on_regression_RF(xc_part,yc_reg)\n",
    "end = timer()\n",
    "print(f'Random Forest Model on Data Subset Complete in {end-start} seconds')\n",
    "\n",
    "start = timer()  \n",
    "boost_rmse,boost_r2 = run_cross_validation_on_regression_Boost(xc_full,yc_reg)\n",
    "end = timer()\n",
    "print(f'Boosted Trees Model on Full Dataset Complete in {end-start} seconds')\n",
    "\n",
    "start = timer()  \n",
    "boost_part_rmse,boost_part_r2 = run_cross_validation_on_regression_Boost(xc_part,yc_reg)\n",
    "end = timer()\n",
    "print(f'Boosted Trees Model on Data Subset Complete in {end-start} seconds')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7e27255",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Corn Regression results\n",
    "c_result_ds_list  = [['Linear Run 1','Subset',linear_rmse,linear_r2]\n",
    "                    ,['ENet Run 1','Full',enet_full_rmse,enet_full_r2]\n",
    "                    ,['Ridge Run 1','Subset',ridge_part_rmse,ridge_part_r2]\n",
    "                    ,['Random Forest Run 1','Subset',rfr_rmse,rfr_r2]\n",
    "                    ,['Boosted Trees Run 1','Full',boost_rmse,boost_r2]\n",
    "                    ,['Boosted Trees Run 2','Subset',boost_part_rmse,boost_part_r2]]\n",
    "results_delivery_count = pd.DataFrame(c_result_ds_list,columns=['Model','Dataset','RMSE','R^2'])\n",
    "results_delivery_count.sort_values(['RMSE','R_Squared'],ascending=[True,False])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7837eaf",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Corn Classfication\n",
    "start = timer()\n",
    "log_accuracy_part = run_logistic(xc_part,yc_class,graph=True)\n",
    "end = timer()\n",
    "print(f'Logistic Model on Data Subset Complete in {end-start} seconds')\n",
    "\n",
    "start = timer()\n",
    "rda_accuracy_full = run_RDA_classification(xc_full,yc_class,graph=True)\n",
    "end = timer()\n",
    "print(f'RDA Model on Full Data Complete in {end-start} seconds')\n",
    "\n",
    "start = timer()\n",
    "rda_accuracy_part = run_RDA_classification(xc_part,yc_class,graph=True)\n",
    "end = timer()\n",
    "print(f'RDA Model on Data Subset Complete in {end-start} seconds')\n",
    "\n",
    "start = timer()\n",
    "rf_accuracy_part = run_cross_validation_on_classification_RF(xc_part,yc_class,graph=True)\n",
    "end = timer()\n",
    "print(f'Random Forest Model on Data Subset Complete in {end-start} seconds')\n",
    "\n",
    "start = timer()\n",
    "boost_accuracy_full = run_cross_validation_on_classification_Boost(xc_full,yc_class,graph=True)\n",
    "end = timer()\n",
    "print(f'Boosted Trees Model on Full Dataset Complete in {end-start} seconds')\n",
    "\n",
    "start = timer()\n",
    "boost_accuracy_part = run_cross_validation_on_classification_Boost(xc_part,yc_class,graph=True)\n",
    "end = timer()\n",
    "print(f'Boosted Trees Model on Data Subset Complete in {end-start} seconds')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6bfc67ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "#corn Classification Results\n",
    "#create a data frame of the results for analysis\n",
    "c_result_aa_list  = [['Logistic Run 1','Partial',log_accuracy_part]\n",
    "                    ,['RDA Run 1','Full',rda_accuracy_full]\n",
    "                    ,['RDA Run 2','Partial',rda_accuracy_part]\n",
    "                    ,['Random Forest Run 1','Partial',rf_accuracy_part]\n",
    "                    ,['Boosted Trees Run 1','Full',boost_accuracy_full]\n",
    "                    ,['Boosted Trees Run 2','Partial',boost_accuracy_part]]\n",
    "results_above_average = pd.DataFrame(c_result_aa_list,columns=['Model','Dataset','Accuracy'])\n",
    "results_above_average.sort_values(['Accuracy'],ascending=[False])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ff464c5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
