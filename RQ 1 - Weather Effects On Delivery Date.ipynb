{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fccde9a6",
   "metadata": {},
   "source": [
    "## Does weather play a factor in when deliveries occur?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fedd4ab3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import Libraries\n",
    "import os\n",
    "import pandas as pd \n",
    "import numpy as np \n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns \n",
    "import statsmodels.api as sm\n",
    "from sklearn.linear_model import LinearRegression,LogisticRegressionCV,LassoCV,ElasticNet,ElasticNetCV,RidgeCV,RidgeClassifierCV,ridge_regression\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "from statsmodels.formula.api import ols\n",
    "from statsmodels.stats.anova import anova_lm\n",
    "from statsmodels.stats.outliers_influence import variance_inflation_factor\n",
    "from sklearn.model_selection import KFold, StratifiedKFold, train_test_split, cross_val_score,cross_val_predict,RepeatedStratifiedKFold,RepeatedKFold\n",
    "from sklearn.metrics import r2_score, mean_squared_error, confusion_matrix, ConfusionMatrixDisplay, roc_auc_score\n",
    "from sklearn.ensemble import GradientBoostingClassifier, GradientBoostingRegressor, RandomForestClassifier, RandomForestRegressor\n",
    "#need \"pip install scikit-optimize\"\n",
    "from skopt.searchcv import BayesSearchCV\n",
    "from skopt.utils import use_named_args\n",
    "from skopt import gp_minimize\n",
    "from timeit import default_timer as timer\n",
    "from sklearn.tree import plot_tree\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3303ba89",
   "metadata": {},
   "outputs": [],
   "source": [
    "#functions to perform graphing\n",
    "def graph_it(y_true,y_pred,title=\"Graph\",RQ=1):\n",
    "# do the different graphing\n",
    "    plt.rcParams.update({'font.sans-serif':'Arial'})\n",
    "\n",
    "    if (RQ == 1):\n",
    "        lables = np.array(False,True)\n",
    "    else: labels = np.array(['More_Activity','Same_Activity','Less_Activity'])\n",
    "    \n",
    "    #confusion matrix\n",
    "    cm = confusion_matrix(y_true,y_pred,labels=labels)\n",
    "    disp = ConfusionMatrixDisplay(confusion_matrix=cm,display_labels=labels)\n",
    "    disp.plot(cmap='Greys',colorbar=False)\n",
    "    plt.title(title)            \n",
    "    plt.show()\n",
    "\n",
    "def graph_feature(names,fi,graph_title,thresh=5,tree=True,add_label=True):\n",
    "    sort_key = fi.argsort()\n",
    "    plt.figure(figsize=(5,10))\n",
    "    bars = plt.barh(names[sort_key],fi[sort_key],color='lightgrey',edgecolor='black')\n",
    "    plt.title(graph_title)\n",
    "    \n",
    "    if (add_label==True and tree==True):\n",
    "        # Add annotation to top 5 bars\n",
    "        plt.xlabel('Feature Importance')        \n",
    "        full_count=len(bars)\n",
    "        exit_count=full_count\n",
    "        for bar in bars:\n",
    "            if(exit_count > 5):\n",
    "                exit_count = exit_count -1\n",
    "                continue\n",
    "            else:\n",
    "                width = bar.get_width()\n",
    "                label_y = bar.get_y() + bar.get_height()/4\n",
    "                plt.text(.01, label_y, s=f'{width:.4f}',fontweight='bold',color='black')\n",
    "                exit_count = exit_count - 1\n",
    "    elif (add_label==True and tree==False):\n",
    "        # Add annotation to top and bottom 3 bars\n",
    "        plt.xlabel('Coefficients') \n",
    "        full_count=len(bars)\n",
    "        exit_count=full_count\n",
    "        for bar in bars:\n",
    "            if(exit_count > thresh and exit_count <= full_count-thresh ):\n",
    "                exit_count = exit_count -1\n",
    "                continue\n",
    "            else:\n",
    "                width = bar.get_width()\n",
    "                if (width > 0):\n",
    "                    plot_width = width-width+width/250\n",
    "                else:plot_width = width-width+width/1000\n",
    "                label_y = bar.get_y() + bar.get_height() /4\n",
    "                plt.text(plot_width, label_y, s=f'{width:.4f}',fontweight='bold',color='black')\n",
    "                exit_count = exit_count - 1    \n",
    "           \n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95d83e5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#load dataset into a dataframe and confirm values\n",
    "full_start = timer()\n",
    "df_raw = pd.read_csv('DataSets\\\\Savage_Daily_Ticket_Count_Weather_Export.csv')\n",
    "df_raw.head(12)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff7006d9",
   "metadata": {},
   "source": [
    "Response varaibles are:  \n",
    "delivery_count_sum -> total deliveries for the date\n",
    "\n",
    "log_ratio_to_average -> ratio of today's deliveries to the average on that day for the last 11 years (log transformed to normallize)\n",
    "\n",
    "is_above_average_delivery_day -> to try logistic regression:  True if greater than the average"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df129a96",
   "metadata": {},
   "outputs": [],
   "source": [
    "#establish the working set\n",
    "df = df_raw.copy()\n",
    "\n",
    "#don't need the delivery date field for analysis nor the day name\n",
    "df = df.drop(['delivery_date','delivery_weekday_name'],axis=1)\n",
    "\n",
    "#set values to string for analysis\n",
    "df['SnowOnGround'] = df['SnowOnGround'].astype(str)\n",
    "df['is_midweek'] = df['is_midweek'].astype(str)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d43c45c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Correlations have been checked in dataset building, but will put a matrix up for completeness\n",
    "corr = df_raw.corr()\n",
    "corr.style.background_gradient(cmap='coolwarm')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38e26344",
   "metadata": {},
   "outputs": [],
   "source": [
    "#function to handle multi-collinearity tests\n",
    "def vif_calc(X):\n",
    "    vif_info = pd.DataFrame()\n",
    "    vif_info['VIF'] = [variance_inflation_factor(X.values, i) for i in range(X.shape[1])]\n",
    "    vif_info['Column'] = X.columns\n",
    "    vif_info.sort_values('VIF', ascending=False)\n",
    "    return(vif_info)\n",
    "\n",
    "#function to pass back AIC for linear model\n",
    "\n",
    "def aic_calc(X,Y):\n",
    "    #add constant to predictor variables\n",
    "    X = sm.add_constant(X)\n",
    "    #fit regression model\n",
    "    model = sm.OLS(Y, X).fit()\n",
    "    return(model.aic)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6630c26b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#create data sets for analysis, keep x's separate in case I change individual tests first is regression against the delivery count\n",
    "xc_full = df.drop(['delivery_count_sum','is_above_average_delivery_day','log_ratio_to_average'],axis=1)\n",
    "xc_full = pd.get_dummies(xc_full,drop_first = True)                #make dummies for categorical values for analysis\n",
    "yc = df['delivery_count_sum']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f787007",
   "metadata": {},
   "outputs": [],
   "source": [
    "vif_calc(xc_full)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9c84ce3",
   "metadata": {},
   "source": [
    "This data (as expected) has columns that have correlations.  In general the \"Diff\" fields are better distributed than the \"Amt\" so we will remove and run this again.  Also remove the \"no precip\" fields since they have high correlations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f364cec1",
   "metadata": {},
   "outputs": [],
   "source": [
    "temp_xc = xc_full.drop(['PriorDayPrecipitationAmt','Prior2DayPrecipitationAmt','PriorDaySnowfallAmt','Precip_12AM-6AM_No Precip','Precip_6AM-10AM_No Precip','Precip_6AM-12PM_No Precip','Precip_10AM-2PM_No Precip'],axis=1)\n",
    "vif_calc(temp_xc)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "229eb1ec",
   "metadata": {},
   "source": [
    "All looking good except need to pick which Temperature Diff field to keep. Check for lowest AIC from keeping 1 of them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa02e36a",
   "metadata": {},
   "outputs": [],
   "source": [
    "aic_val =np.empty(4)\n",
    "aic_val[0] = aic_calc(temp_xc,yc)\n",
    "temp_x = temp_xc.drop(['PriorDayMaximumTemperatureDiff','PriorDayMinimumTemperatureDiff'],axis=1)\n",
    "aic_val[1] = aic_calc(temp_x,yc)\n",
    "temp_x = temp_xc.drop(['PriorDayMinimumTemperatureDiff','PriorDayAverageDryBulbTemperatureDiff'],axis=1)\n",
    "aic_val[2] = aic_calc(temp_x,yc)\n",
    "temp_x = temp_xc.drop(['PriorDayMaximumTemperatureDiff','PriorDayAverageDryBulbTemperatureDiff'],axis=1)\n",
    "aic_val[3] = aic_calc(temp_x,yc)\n",
    "print(aic_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ccf93678",
   "metadata": {},
   "outputs": [],
   "source": [
    "xc_part = temp_xc.drop(['PriorDayMaximumTemperatureDiff','PriorDayAverageDryBulbTemperatureDiff'],axis=1)\n",
    "vif_calc(xc_part)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d22016d",
   "metadata": {},
   "source": [
    "I now have a full datasets and a subset of data that has strong VIF stats.  I will run linear regression to get a baseline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0d933e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#function to run baseline regression\n",
    "def get_stats(x,y,log=False):\n",
    "    if (log == True):\n",
    "        results = sm.Logit(y,x).fit()\n",
    "    else: results = sm.OLS(y,x).fit()\n",
    "    print(results.summary())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d80ea05",
   "metadata": {},
   "outputs": [],
   "source": [
    "#do linear regression on the full (for comparison) and then on the partial removing non-signficant p-values\n",
    "#real models will have test/train data\n",
    "get_stats(xc_full,yc)\n",
    "\n",
    "get_stats(xc_part,yc) \n",
    "temp_xc = xc_part.drop(['PriorDaySnowfallDiff','Precip_10AM-2PM_Precip'],axis=1)\n",
    "get_stats(temp_xc,yc) \n",
    "\n",
    "temp_xc = temp_xc.drop(['DailySnowDepth','DailySnowfall','Precip_6AM-10AM_Precip','Precip_6AM-12PM_Precip'],axis=1)\n",
    "get_stats(temp_xc,yc) \n",
    "\n",
    "#capture the dataset used by linear regression\n",
    "xc_sp = temp_xc\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34941ec2",
   "metadata": {},
   "source": [
    "set up models:  \n",
    "\n",
    "Lasso & Elastic Net and \"boosting\" for of decisions trees for the full models (since they do various measures of feature selection) .\n",
    "\n",
    "Ridge Regression and Random Forests for the partial datasets since they work better on models that don't have collinearity issues (which we've addressed).\n",
    "\n",
    "In all cases, I will utilize cross validation on all the data to find the \"Best\" model, and then use a train/test set to get the  root mean squared error and R^2 values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb8087f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_linear(X,Y,graph=False,graph_title='Regression Graph'):\n",
    "    #X = predictors, Y = response, log determines if we are using linear or logistic regression\n",
    "    #first step is to use a Bayes Search algorithm to find the optimal hyperparameters\n",
    "    #define hyperparameters to search   \n",
    "    hyper_params = {\n",
    "        'fit_intercept' : [True,False],\n",
    "        'positive' : [True,False]\n",
    "    }    \n",
    "    cv = KFold(n_splits = 10,shuffle=True,random_state=5440)   #set random_state to make results repeatable\n",
    "    search = BayesSearchCV(\n",
    "        estimator=LinearRegression(),\n",
    "        search_spaces=hyper_params,\n",
    "        n_jobs=-1,\n",
    "        cv=cv,\n",
    "        n_iter=10,\n",
    "        #scoring=\"accuracy\",  -- leave as default which is based on the estimator\n",
    "        verbose=0,\n",
    "        random_state=5440\n",
    "    )\n",
    "    #scale the x predictor values and then run the Bayesian search and capture best parameters\n",
    "    scaler = StandardScaler()\n",
    "    x_scaled = scaler.fit_transform(X)       \n",
    "    search.fit(x_scaled,Y)    \n",
    "    best_params = search.best_params_\n",
    "    print(graph_title,file=open('RQ1_hyperparameters','a'))\n",
    "    print(best_params,file=open('RQ1_hyperparameters','a'))\n",
    "    \n",
    "    #X = predictors, Y = response, log determines if we are using linear or logistic regression\n",
    "    x_train,x_test,y_train,y_test = train_test_split(x_scaled,Y,test_size=.24,random_state=5440)   \n",
    "\n",
    "    model = LinearRegression(n_jobs=-1,fit_intercept=best_params['fit_intercept'],positive=best_params['positive'])\n",
    "    model.fit(x_train,y_train)\n",
    "    pred_test = model.predict(x_test)\n",
    "    rmse_test = np.sqrt(mean_squared_error(y_test,pred_test))\n",
    "    r2_test = r2_score(y_test, pred_test)  \n",
    "    \n",
    "    if graph:\n",
    "        graph_feature(X.columns,model.coef_,graph_title,tree=False)\n",
    "    \n",
    "    return(rmse_test,r2_test)\n",
    "    \n",
    "# function for fitting trees of various depths for Random Forests\n",
    "def run_cross_validation_on_regression_RF(X, Y,graph=False,graph_title='Regression Graph'):\n",
    "    #X = predictors, Y = response, log determines if we are using linear or logistic regression\n",
    "    #first step is to use a Bayes Search algorithm to find the optimal hyperparameters\n",
    "    #define hyperparameters to search   \n",
    "    hyper_params = {\n",
    "        'n_estimators': [200, 400, 600, 800, 1000],\n",
    "        'max_depth': (1, 9),\n",
    "        'criterion': ['squared_error','poisson'], #can use poisson if not negative\n",
    "        'max_features' : [.250,.3333,.375]\n",
    "    }\n",
    "    cv = KFold(n_splits = 5,shuffle=True,random_state=5440)   #set random_state to make results repeatable\n",
    "    search = BayesSearchCV(\n",
    "        estimator=RandomForestRegressor(),\n",
    "        search_spaces=hyper_params,\n",
    "        n_jobs=-1,\n",
    "        cv=cv,\n",
    "        n_iter=125,\n",
    "        #scoring=\"accuracy\",\n",
    "        verbose=0,\n",
    "        random_state=5440\n",
    "    )\n",
    "    \n",
    "    search.fit(X,Y)    \n",
    "    best_params = search.best_params_\n",
    "    print(graph_title,file=open('RQ1_hyperparameters','a'))\n",
    "    print(best_params,file=open('RQ1_hyperparameters','a'))\n",
    "    \n",
    "    #now that the best parameters are found, split the data, run on a test dataset and then predict results\n",
    "    x_train,x_test,y_train,y_test = train_test_split(X,Y,test_size=.24,random_state=5440)\n",
    "    model = RandomForestRegressor(n_estimators=best_params['n_estimators'],max_depth=best_params['max_depth']\n",
    "                                   ,criterion=best_params['criterion'],max_features=best_params['max_features'])\n",
    "    model.fit(x_train,y_train)\n",
    "    pred_test = model.predict(x_test)    \n",
    "    rmse_test = np.sqrt(mean_squared_error(y_test,pred_test))\n",
    "    r2_test = r2_score(y_test, pred_test)  \n",
    "    \n",
    "    if graph:\n",
    "        graph_feature(X.columns,model.feature_importances_,graph_title)\n",
    "    \n",
    "    return(rmse_test,r2_test)\n",
    "\n",
    "# function for fitting trees of various depths for Boosted Version\n",
    "def run_cross_validation_on_regression_Boost(X, Y,graph=False,graph_title='Regression Graph'):\n",
    "    #X = predictors, Y = response\n",
    "    #first step is to use a Bayes Search algorithm to find the optimal hyperparameters\n",
    "    #define hyperparameters to search   \n",
    "    hyper_params = {\n",
    "        'n_estimators': [500, 600, 700, 800, 900, 1000],\n",
    "        'max_depth': (1, 9),\n",
    "        'criterion': ['friedman_mse','squared_error'],\n",
    "        'loss' : ['squared_error','absolute_error','huber'],\n",
    "        'max_features' : [.250,.3333,.375]\n",
    "    }    \n",
    "    cv = KFold(n_splits = 5,shuffle=True,random_state=5440)   #set random_state to make results repeatable\n",
    "    search = BayesSearchCV(\n",
    "        estimator=GradientBoostingRegressor(),\n",
    "        search_spaces=hyper_params,\n",
    "        n_jobs=-1,\n",
    "        cv=cv,\n",
    "        n_iter=150,\n",
    "        #scoring=\"accuracy\",\n",
    "        verbose=0,\n",
    "        random_state=5440\n",
    "    )\n",
    "    \n",
    "    search.fit(X,Y)    \n",
    "    best_params = search.best_params_\n",
    "    print(graph_title,file=open('RQ1_hyperparameters','a'))\n",
    "    print(best_params,file=open('RQ1_hyperparameters','a'))\n",
    "    \n",
    "    #now that the best parameters are found, split the data, run on a test dataset and then predict results\n",
    "    x_train,x_test,y_train,y_test = train_test_split(X,Y,test_size=.24,random_state=5440)\n",
    "    model = GradientBoostingRegressor(n_estimators=best_params['n_estimators'],max_depth=best_params['max_depth']\n",
    "                                   ,criterion=best_params['criterion'],loss=best_params['loss'],max_features=best_params['max_features'])\n",
    "    model.fit(x_train,y_train)\n",
    "    pred_test = model.predict(x_test)\n",
    "    rmse_test = np.sqrt(mean_squared_error(y_test,pred_test))\n",
    "    r2_test = r2_score(y_test, pred_test)  \n",
    "    \n",
    "    if graph:\n",
    "        graph_feature(X.columns,model.feature_importances_,graph_title)\n",
    "    \n",
    "    return(rmse_test,r2_test)\n",
    "\n",
    "#enet regression:  handles E-Net and Lasso\n",
    "def run_enet_regression(X,Y,graph=False,graph_title='Regression Graph'):\n",
    "    #X = predictors, Y = response, log determines if we are using linear or logistic regression\n",
    "    #first step is to use a Bayes Search algorithm to find the optimal hyperparameters\n",
    "    #define hyperparameters to search   \n",
    "    hyper_params = {\n",
    "        'alpha' : [.0001,.0005,.001,.005,.01,.05,.1,.5,1.0,5,10,50,100,500,1000],\n",
    "        'l1_ratio' : [.01,.05,.1,.3,.5,.7,.9,.95,.99,1],\n",
    "        'fit_intercept' : [True,False]\n",
    "    }    \n",
    "    cv = KFold(n_splits = 5,shuffle=True,random_state=5440)   #set random_state to make results repeatable\n",
    "    search = BayesSearchCV(\n",
    "        estimator=ElasticNet(),\n",
    "        search_spaces=hyper_params,\n",
    "        n_jobs=-1,\n",
    "        cv=cv,\n",
    "        n_iter=200,\n",
    "        #scoring=\"accuracy\",  -- leave as default which is based on the estimator\n",
    "        verbose=0,\n",
    "        random_state=5440\n",
    "    )\n",
    "    #scale the x predictor values and then run the Bayesian search and capture best parameters\n",
    "    scaler = StandardScaler()\n",
    "    x_scaled = scaler.fit_transform(X)       \n",
    "    search.fit(x_scaled,Y)    \n",
    "    best_params = search.best_params_\n",
    "    print(graph_title,file=open('RQ1_hyperparameters','a'))\n",
    "    print(best_params,file=open('RQ1_hyperparameters','a'))\n",
    "    \n",
    "    #X = predictors, Y = response, log determines if we are using linear or logistic regression\n",
    "    x_train,x_test,y_train,y_test = train_test_split(x_scaled,Y,test_size=.24,random_state=5440)   \n",
    "\n",
    "    model = ElasticNet(fit_intercept=best_params['fit_intercept'],alpha=best_params['alpha'],\n",
    "                         l1_ratio=best_params['l1_ratio'],random_state=5440)\n",
    "    model.fit(x_train,y_train)\n",
    "    pred_test = model.predict(x_test)\n",
    "    rmse_test = np.sqrt(mean_squared_error(y_test,pred_test))\n",
    "    r2_test = r2_score(y_test, pred_test)  \n",
    "    \n",
    "    if graph:\n",
    "        graph_feature(X.columns,model.coef_,graph_title,tree=False)\n",
    "    \n",
    "    return(rmse_test,r2_test)\n",
    "\n",
    "#ridge regression:  handles Ridge separately due to different hyperparameters and lack of feature selection\n",
    "def run_ridge_regression(X,Y,graph=False,graph_title='Regression Graph'):\n",
    "    #X = predictors, Y = response, log determines if we are using linear or logistic regression\n",
    "\n",
    "    #scale the x predictor values and then run the Bayesian search and capture best parameters\n",
    "    scaler = StandardScaler()\n",
    "    x_scaled = scaler.fit_transform(X)       \n",
    "   \n",
    "    cv = RepeatedKFold(n_splits = 5,n_repeats=75,random_state=5440)  \n",
    "    model = RidgeCV(alphas=[.0001,.0005,.001,.005,.01,.05,.1,.5,1.0,5,10,50,100,500,1000],cv=cv)\n",
    "    model.fit(x_scaled,Y)\n",
    "    print(graph_title,file=open('RQ1_hyperparameters','a'))\n",
    "    print(model.alpha_,file=open('RQ1_hyperparameters','a'))\n",
    "    \n",
    "    #X = predictors, Y = response, log determines if we are using linear or logistic regression\n",
    "    x_train,x_test,y_train,y_test = train_test_split(x_scaled,Y,test_size=.24,random_state=5440)   \n",
    "\n",
    "    pred_test = model.predict(x_test)\n",
    "    rmse_test = np.sqrt(mean_squared_error(y_test,pred_test))\n",
    "    r2_test = r2_score(y_test, pred_test)  \n",
    "    \n",
    "    if graph:\n",
    "        graph_feature(X.columns,model.coef_,graph_title,tree=False)\n",
    "    \n",
    "    return(rmse_test,r2_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5b92cc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "start = timer()\n",
    "linear_rmse,linear_r2 = run_linear(xc_part,yc,graph=True,graph_title=\"Weather Only - Linear Regression - Partial\")\n",
    "end = timer()\n",
    "print(f'Linear Model on Data Subset Complete in {end-start} seconds')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec5529d3",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# With the regression functions defined, run the regressions and capture the RMSE and R-squared\n",
    "start = timer()\n",
    "linear_rmse,linear_r2 = run_linear(xc_part,yc,graph=True,graph_title=\"Weather Only - Linear Regression - Partial\")\n",
    "end = timer()\n",
    "print(f'Linear Model on Data Subset Complete in {end-start} seconds')\n",
    "\n",
    "start = timer()\n",
    "linear_sp_rmse,linear_sp_r2 = run_linear(xc_sp,yc,graph=True,graph_title=\"Weather Only - Linear Regression - Sig P\")\n",
    "end = timer()\n",
    "print(f'Linear Model on Significant P Values Complete in {end-start} seconds')\n",
    "\n",
    "start = timer()      \n",
    "enet_full_rmse,enet_full_r2 = run_enet_regression(xc_full,yc,graph=True,graph_title=\"Weather Only - Lasso/ENet Regression - Full\")\n",
    "end = timer()\n",
    "print(f'Enet Regression Model on Full Dataset Complete in {end-start} seconds')\n",
    "\n",
    "start = timer()  \n",
    "ridge_part_rmse,ridge_part_r2 = run_ridge_regression(xc_part,yc,graph=True,graph_title=\"Weather Only - Ridge Regression - Partial\")\n",
    "end = timer()\n",
    "print(f'Ridge Regression Model on Data Subset Complete in {end-start} seconds')\n",
    "\n",
    "start = timer()  \n",
    "rfr_rmse,rfr_r2 = run_cross_validation_on_regression_RF(xc_part,yc,graph=True,graph_title=\"Weather Only - Random Forests - Partial\")\n",
    "end = timer()\n",
    "print(f'Random Forest Model on Data Subset Complete in {end-start} seconds')\n",
    "\n",
    "start = timer()  \n",
    "boost_rmse,boost_r2 = run_cross_validation_on_regression_Boost(xc_full,yc,graph=True,graph_title=\"Weather Only - Boosted Trees - Full\")\n",
    "end = timer()\n",
    "print(f'Boosted Trees Model on Full Dataset Complete in {end-start} seconds')\n",
    "\n",
    "start = timer()  \n",
    "boost_part_rmse,boost_part_r2 = run_cross_validation_on_regression_Boost(xc_part,yc,graph=True,graph_title=\"Weather Only - Boosted Trees - Partial\")\n",
    "end = timer()\n",
    "print(f'Boosted Trees Model on Data Subset Complete in {end-start} seconds')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41fef1af",
   "metadata": {},
   "outputs": [],
   "source": [
    "#create a data frame of the results for analysis\n",
    "result_ds_list  = [['Linear Run 1','Subset',linear_rmse,linear_r2]\n",
    "                  ,['Linear Run 2','SigP',linear_sp_rmse,linear_sp_r2]\n",
    "                  ,['ENet Run 1','Full',enet_full_rmse,enet_full_r2]\n",
    "                  ,['Ridge Run 1','Subset',ridge_part_rmse,ridge_part_r2]\n",
    "                  ,['Random Forest Run 1','Subset',rfr_rmse,rfr_r2]\n",
    "                  ,['Boosted Trees Run 1','Full',boost_rmse,boost_r2]\n",
    "                  ,['Boosted Trees Run 2','Subset',boost_part_rmse,boost_part_r2]]\n",
    "results_delivery_count = pd.DataFrame(result_ds_list,columns=['Model','Dataset','RMSE','R^2'])\n",
    "sort_results = results_delivery_count.sort_values(['R^2','RMSE'],ascending=[False,True])\n",
    "sort_results.to_excel('RQ1_Regression_Count.xlsx')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93c7c54e",
   "metadata": {},
   "source": [
    "There doesn't look to be any predictive power in looking at weather against the daily delivery count.  Next we will look at the ratio of that days loads above average.  I will use the same methods to develop the datasets and run the same tests.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35369cdf",
   "metadata": {},
   "outputs": [],
   "source": [
    "xr_full = df.drop(['delivery_count_sum','is_above_average_delivery_day','log_ratio_to_average'],axis=1)\n",
    "xr_full = pd.get_dummies(xr_full,drop_first = True)                #make dummies for categorical values for analysis\n",
    "yr = df['log_ratio_to_average']\n",
    "xr_part = xr_full.drop(['PriorDayPrecipitationAmt','Prior2DayPrecipitationAmt','PriorDaySnowfallAmt','Precip_12AM-6AM_No Precip','Precip_6AM-10AM_No Precip','Precip_6AM-12PM_No Precip','Precip_10AM-2PM_No Precip'],axis=1)\n",
    "vif_calc(xr_part)\n",
    "\n",
    "aic_val =np.empty(4)\n",
    "aic_val[0] = aic_calc(xr_part,yr)\n",
    "temp_x = xr_part.drop(['PriorDayMaximumTemperatureDiff','PriorDayMinimumTemperatureDiff'],axis=1)\n",
    "aic_val[1] = aic_calc(temp_x,yr)\n",
    "temp_x = xr_part.drop(['PriorDayMinimumTemperatureDiff','PriorDayAverageDryBulbTemperatureDiff'],axis=1)\n",
    "aic_val[2] = aic_calc(temp_x,yr)\n",
    "temp_x = xr_part.drop(['PriorDayMaximumTemperatureDiff','PriorDayAverageDryBulbTemperatureDiff'],axis=1)\n",
    "aic_val[3] = aic_calc(temp_x,yr)\n",
    "print(aic_val)\n",
    "\n",
    "xr_part = xr_part.drop(['PriorDayMinimumTemperatureDiff','PriorDayAverageDryBulbTemperatureDiff'],axis=1)\n",
    "vif_calc(xr_part)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1bbd94a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#get the significant variables for linear regression and find the proper tuning parametners for Lasso/E-Net\n",
    "get_stats(xr_part,yr) \n",
    "temp_xr = xr_part.drop(['PriorDayMaximumTemperatureDiff','Precip_12AM-6AM_Precip','Precip_6AM-10AM_Precip','Precip_6AM-12PM_Precip','Precip_10AM-2PM_Precip'],axis=1)\n",
    "get_stats(temp_xr,yr)\n",
    "xr_sp = temp_xr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35ca72f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# With the regression functions defined, run the regressions and capture the RMSE and R-squared\n",
    "start = timer()\n",
    "linear_rmse,linear_r2 = run_linear(xr_part,yr,graph=True,graph_title=\"Weather Only - Linear Regression 2 - Partial\")\n",
    "end = timer()\n",
    "print(f'Linear Model on Data Subset Complete in {end-start} seconds')\n",
    "\n",
    "start = timer()\n",
    "linear_sp_rmse,linear_sp_r2 = run_linear(xr_sp,yr,graph=True,graph_title=\"Weather Only - Linear Regression 2 - Sig P\")\n",
    "end = timer()\n",
    "print(f'Linear Model on Significant P Values Complete in {end-start} seconds')\n",
    "\n",
    "start = timer()      \n",
    "enet_full_rmse,enet_full_r2 = run_enet_regression(xr_full,yr,graph=True,graph_title=\"Weather Only - Lasso/ENet Regression 2 - Full\")\n",
    "end = timer()\n",
    "print(f'Enet Regression Model on Full Dataset Complete in {end-start} seconds')\n",
    "\n",
    "start = timer()  \n",
    "ridge_part_rmse,ridge_part_r2 = run_ridge_regression(xr_part,yr,graph=True,graph_title=\"Weather Only - Ridge Regression 2 - Partial\")\n",
    "end = timer()\n",
    "print(f'Ridge Regression Model on Data Subset Complete in {end-start} seconds')\n",
    "\n",
    "start = timer()  \n",
    "rfr_rmse,rfr_r2 = run_cross_validation_on_regression_RF(xr_part,yr,graph=True,graph_title=\"Weather Only - Random Forests 2 - Partial\")\n",
    "end = timer()\n",
    "print(f'Random Forest Model on Data Subset Complete in {end-start} seconds')\n",
    "\n",
    "start = timer()  \n",
    "boost_rmse,boost_r2 = run_cross_validation_on_regression_Boost(xr_full,yr,graph=True,graph_title=\"Weather Only - Boosted Trees 2 - Full\")\n",
    "end = timer()\n",
    "print(f'Boosted Trees Model on Full Dataset Complete in {end-start} seconds')\n",
    "\n",
    "start = timer()  \n",
    "boost_part_rmse,boost_part_r2 = run_cross_validation_on_regression_Boost(xr_part,yr,graph=True,graph_title=\"Weather Only - Boosted Trees 2 - Partial\")\n",
    "end = timer()\n",
    "print(f'Boosted Trees Model on Data Subset Complete in {end-start} seconds')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6747acaf",
   "metadata": {},
   "outputs": [],
   "source": [
    "#create a data frame of the results for analysis\n",
    "result_ra_list  = [['Linear Run 1','Subset',linear_rmse,linear_r2]\n",
    "                  ,['Linear Run 2','SigP',linear_sp_rmse,linear_sp_r2]\n",
    "                  ,['Enet Run 1','Full',enet_full_rmse,enet_full_r2]\n",
    "                  ,['Ridge Run 1','Subset',ridge_part_rmse,ridge_part_r2]\n",
    "                  ,['Random Forest Run 1','Subset',rfr_rmse,rfr_r2]\n",
    "                  ,['Boosted Trees Run 1','Full',boost_rmse,boost_r2]\n",
    "                  ,['Boosted Trees Run 2','Subset',boost_part_rmse,boost_part_r2]]\n",
    "results_delivery_count = pd.DataFrame(result_ra_list,columns=['Model','Dataset','RMSE','R^2'])\n",
    "sort_results = results_delivery_count.sort_values(['R^2','RMSE'],ascending=[False,True])\n",
    "sort_results.to_excel('RQ1_Regression_Ratio.xlsx')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d5e24d8",
   "metadata": {},
   "source": [
    "Actually worse values.  A bit suprised the ensemble methods are not doing better.  Next step will do a logistic/classification."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16122337",
   "metadata": {},
   "outputs": [],
   "source": [
    "xl_full = df.drop(['delivery_count_sum','is_above_average_delivery_day','log_ratio_to_average'],axis=1)\n",
    "xl_full = pd.get_dummies(xl_full,drop_first = True)                #make dummies for categorical values for analysis\n",
    "yl = df['is_above_average_delivery_day']\n",
    "\n",
    "xl_part = xl_full.drop(['PriorDayPrecipitationAmt','Prior2DayPrecipitationAmt','PriorDaySnowfallAmt','Precip_12AM-6AM_No Precip','Precip_6AM-10AM_No Precip','Precip_6AM-12PM_No Precip','Precip_10AM-2PM_No Precip'],axis=1)\n",
    "vif_calc(xl_part)\n",
    "\n",
    "aic_val =np.empty(4)\n",
    "aic_val[0] = aic_calc(xl_part,yl)\n",
    "temp_x = xl_part.drop(['PriorDayMaximumTemperatureDiff','PriorDayMinimumTemperatureDiff'],axis=1)\n",
    "aic_val[1] = aic_calc(temp_x,yl)\n",
    "temp_x = xl_part.drop(['PriorDayMinimumTemperatureDiff','PriorDayAverageDryBulbTemperatureDiff'],axis=1)\n",
    "aic_val[2] = aic_calc(temp_x,yl)\n",
    "temp_x = xl_part.drop(['PriorDayMaximumTemperatureDiff','PriorDayAverageDryBulbTemperatureDiff'],axis=1)\n",
    "aic_val[3] = aic_calc(temp_x,yl)\n",
    "print(aic_val)\n",
    "\n",
    "xl_part = xl_part.drop(['PriorDayMaximumTemperatureDiff','PriorDayAverageDryBulbTemperatureDiff'],axis=1)\n",
    "vif_calc(xl_part)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4976625",
   "metadata": {},
   "source": [
    "Going to utilize 2 datasets in this case -- removing the multi-collinearity is the biggest thing.  Will do a similar bag of models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d412354d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_logistic(X,Y,graph=False,graph_title='Classification Graph'):\n",
    "    #X = predictors, Y = response, log determines if we are using linear or logistic regression\n",
    "    #first step is to use a Bayes Search algorithm to find the optimal hyperparameters\n",
    "    #define hyperparameters to search   \n",
    "    hyper_params = {\n",
    "        'fit_intercept' : [True,False],\n",
    "        'solver' : ['newton-cg', 'lbfgs', 'liblinear', 'sag', 'saga']\n",
    "    }    \n",
    "    cv = StratifiedKFold(n_splits = 10,shuffle=True,random_state=5440)   #set random_state to make results repeatable\n",
    "    search = BayesSearchCV(\n",
    "        estimator=LogisticRegressionCV(),\n",
    "        search_spaces=hyper_params,\n",
    "        n_jobs=-1,\n",
    "        cv=cv,\n",
    "        n_iter=50,\n",
    "        scoring=\"accuracy\",\n",
    "        verbose=0,\n",
    "        random_state=5440\n",
    "    )\n",
    "    #scale the x predictor values and then run the Bayesian search and capture best parameters\n",
    "    scaler = StandardScaler()\n",
    "    x_scaled = scaler.fit_transform(X)       \n",
    "    search.fit(x_scaled,Y)    \n",
    "    best_params = search.best_params_\n",
    "    print(graph_title,file=open('RQ1_hyperparameters','a'))\n",
    "    print(best_params,file=open('RQ1_hyperparameters','a'))\n",
    "    \n",
    "    #now that the best parameters are found, split the data, run on a test dataset and then predict results\n",
    "    x_train,x_test,y_train,y_test = train_test_split(x_scaled,Y,test_size=.24,random_state=5440)\n",
    "    model = LogisticRegressionCV(cv=cv,fit_intercept=best_params['fit_intercept']\n",
    "                                 ,solver=best_params['solver'],scoring='accuracy',n_jobs=-1)\n",
    "    model.fit(x_train,y_train)\n",
    "    pred_test = model.predict(x_test)\n",
    "    test_score = model.score(x_test,y_test)\n",
    "    test_auc = roc_auc_score(y_test,model.predict_proba(x_test))      \n",
    "    class_groups = len(model.coef_)    \n",
    "      \n",
    "    if graph:\n",
    "        graph_it(y_test,pred_test,graph_title,RQ=4)\n",
    "        for cg in range(class_groups):\n",
    "            graph_feature(X.columns,model.coef_[cg],graph_title + ' (\"'+ model.classes_[cg]+ '\" class)',tree=False)\n",
    "\n",
    "    return(test_score,test_auc)\n",
    "\n",
    "# function for fitting trees of various depths using cross-validation\n",
    "def run_cross_validation_on_classification_RF(X, Y,graph=False,graph_title='Classification Graph'):\n",
    "    #X = predictors, Y = response, log determines if we are using linear or logistic regression\n",
    "    #first step is to use a Bayes Search algorithm to find the optimal hyperparameters\n",
    "    #define hyperparameters to search   \n",
    "    hyper_params = {\n",
    "        'n_estimators': [200, 400, 600, 800, 1000],\n",
    "        'max_depth': (1, 9),\n",
    "        'criterion': ['gini', 'entropy'],\n",
    "        'max_features' : ['sqrt','log2']\n",
    "    }    \n",
    "    cv = StratifiedKFold(n_splits = 5,shuffle=True,random_state=5440)   #set random_state to make results repeatable\n",
    "    search = BayesSearchCV(\n",
    "        estimator=RandomForestClassifier(),\n",
    "        search_spaces=hyper_params,\n",
    "        n_jobs=-1,\n",
    "        cv=cv,\n",
    "        n_iter=125,     \n",
    "        scoring=\"accuracy\",\n",
    "        verbose=0,\n",
    "        random_state=5440\n",
    "    )\n",
    "    \n",
    "    search.fit(X,Y)    \n",
    "    best_params = search.best_params_\n",
    "    print(graph_title,file=open('RQ1_hyperparameters','a'))\n",
    "    print(best_params,file=open('RQ1_hyperparameters','a'))\n",
    "    \n",
    "    #now that the best parameters are found, split the data, run on a test dataset and then predict results\n",
    "    x_train,x_test,y_train,y_test = train_test_split(X,Y,test_size=.24,random_state=5440)\n",
    "    model = RandomForestClassifier(n_estimators=best_params['n_estimators'],max_depth=best_params['max_depth']\n",
    "                                   ,criterion=best_params['criterion'],max_features=best_params['max_features'])\n",
    "    model.fit(x_train,y_train)\n",
    "    pred_test = model.predict(x_test)\n",
    "    test_score = model.score(x_test,y_test)\n",
    "    test_auc = roc_auc_score(y_test,model.predict_proba(x_test), multi_class='ovr', average='weighted')     \n",
    "      \n",
    "    if graph:\n",
    "        graph_it(y_test,pred_test,graph_title,RQ=1)\n",
    "        graph_feature(X.columns,model.feature_importances_,graph_title)\n",
    "\n",
    "    return(test_score,test_auc)\n",
    "\n",
    "def run_cross_validation_on_classification_Boost(X, Y,scoring='accuracy',graph=False,graph_title='Classification Graph'):\n",
    "    #X = predictors, Y = response, log determines if we are using linear or logistic regression\n",
    "    #first step is to use a Bayes Search algorithm to find the optimal hyperparameters\n",
    "    #define hyperparameters to search   \n",
    "    hyper_params = {\n",
    "        'n_estimators': [500, 750, 1000, 1250, 1500],\n",
    "        'max_depth': (1, 9),\n",
    "        'criterion': ['friedman_mse', 'squared_error'],\n",
    "        'max_features' : ['sqrt','log2']\n",
    "    }    \n",
    "    cv = StratifiedKFold(n_splits = 5,shuffle=True,random_state=5440)   #set random_state to make results repeatable\n",
    "    search = BayesSearchCV(\n",
    "        estimator=GradientBoostingClassifier(),\n",
    "        search_spaces=hyper_params,\n",
    "        n_jobs=-1,\n",
    "        cv=cv,\n",
    "        n_iter=150,\n",
    "        scoring=\"accuracy\",\n",
    "        verbose=0,\n",
    "        random_state=5440\n",
    "    )\n",
    "    \n",
    "    search.fit(X,Y)    \n",
    "    best_params = search.best_params_\n",
    "    print(graph_title,file=open('RQ1_hyperparameters','a'))\n",
    "    print(best_params,file=open('RQ1_hyperparameters','a'))\n",
    "    \n",
    "    #now that the best parameters are found, split the data, run on a test dataset and then predict results\n",
    "    x_train,x_test,y_train,y_test = train_test_split(X,Y,test_size=.24,random_state=5440)\n",
    "    model = GradientBoostingClassifier(n_estimators=best_params['n_estimators'],max_depth=best_params['max_depth']\n",
    "                                   ,criterion=best_params['criterion'],max_features=best_params['max_features'])\n",
    "    model.fit(x_train,y_train)\n",
    "    pred_test = model.predict(x_test)\n",
    "    test_score = model.score(x_test,y_test)\n",
    "    test_auc = roc_auc_score(y_test,model.predict_proba(x_test), multi_class='ovr', average='weighted')     \n",
    "      \n",
    "    if graph:\n",
    "        graph_it(y_test,pred_test,graph_title,RQ=4)\n",
    "        graph_feature(X.columns,model.feature_importances_,graph_title)\n",
    "\n",
    "    return(test_score,test_auc)\n",
    "\n",
    "\n",
    "#RDA is Regularized Discriminant Analysis (similar to how elastic-net works with Lasso and Ridge)\n",
    "def run_RDA_classification(X,Y,graph=False,graph_title='Classification Graph'):\n",
    "    #X = predictors, Y = response, other numbers for the range of values\n",
    "    \n",
    "    #first step is to use a Bayes Search algorithm to find the optimal hyperparameters\n",
    "    #define hyperparameters to search\n",
    "    hyper_params = {\n",
    "        'solver' : ['lsqr','eigen'],\n",
    "        'shrinkage' : np.arange(0,1.005,.005)\n",
    "    }\n",
    "\n",
    "    search = BayesSearchCV(\n",
    "        estimator=LinearDiscriminantAnalysis(),\n",
    "        search_spaces=hyper_params,\n",
    "        n_jobs=-1,\n",
    "        cv=10,\n",
    "        n_iter=200,\n",
    "        scoring=\"accuracy\",\n",
    "        verbose=0,\n",
    "        random_state=5440\n",
    "    )\n",
    "    \n",
    "    #find the hyperparameters on all the data and capture them for use for training and testing\n",
    "    search.fit(X,Y)    \n",
    "    best_params = search.best_params_\n",
    "    print(graph_title,file=open('RQ1_hyperparameters','a'))\n",
    "    print(best_params,file=open('RQ1_hyperparameters','a'))\n",
    "    \n",
    "    #scale the X values for consistency (though may not have much effect for LDA as it would knn, PCA, gradient decent and ridge/Lasso...)\n",
    "    scaler = StandardScaler()\n",
    "    x_scaled = scaler.fit_transform(X)\n",
    "    x_train,x_test,y_train,y_test = train_test_split(x_scaled,Y,test_size=.24,random_state=5440)\n",
    "    model = LinearDiscriminantAnalysis(shrinkage=best_params['shrinkage'],solver=best_params['solver'])   \n",
    "    #model = LinearDiscriminantAnalysis(shrinkage=.9,solver=best['solver'])  \n",
    "    model.fit(x_train,y_train)\n",
    "     \n",
    "    #find the worth of the model  \n",
    "    pred_test = cross_val_predict(model,x_test,y_test,cv=5,n_jobs=-1)\n",
    "    pred_score = cross_val_score(model,x_test,y_test,cv=5,n_jobs=-1)\n",
    "    test_auc = roc_auc_score(y_test,model.predict_proba(x_test))     \n",
    "    \n",
    "    class_groups = len(model.coef_)\n",
    "    \n",
    "    if graph:\n",
    "        graph_it(y_test,pred_test,graph_title,RQ=4)\n",
    "        for cg in range(class_groups):\n",
    "            graph_feature(X.columns,model.coef_[cg],graph_title + ' (\"'+ model.classes_[cg]+ '\" class)',tree=False)\n",
    "         \n",
    "    return(pred_score.mean(),test_auc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70bb5afb",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "start = timer()\n",
    "log_accuracy_full,log_auc_full = run_logistic(xl_full,yl,graph=True,graph_title=\"Weather Only - Logistic Regression - Full\")\n",
    "end = timer()\n",
    "print(f'Logistic Model on Full Data Complete in {end-start} seconds')\n",
    "\n",
    "start = timer()\n",
    "log_accuracy_part,log_auc_part = run_logistic(xl_part,yl,graph=True,graph_title=\"Weather Only - Logistic Regression - Partial\")\n",
    "end = timer()\n",
    "print(f'Logistic Model on Data Subset Complete in {end-start} seconds')\n",
    "\n",
    "start = timer()\n",
    "rda_accuracy_full,rda_auc_full = run_RDA_classification(xl_full,yl,graph=True,graph_title=\"Weather Only - Discriminant Analysis - Full\")\n",
    "end = timer()\n",
    "print(f'RDA Model on Full Data Complete in {end-start} seconds')\n",
    "\n",
    "start = timer()\n",
    "rda_accuracy_part,rda_auc_part = run_RDA_classification(xl_part,yl,graph=True,graph_title=\"Weather Only - Discriminant Analysis - Partial\")\n",
    "end = timer()\n",
    "print(f'RDA Model on Data Subset Complete in {end-start} seconds')\n",
    "\n",
    "start = timer()\n",
    "rf_accuracy_part,rf_auc_part = run_cross_validation_on_classification_RF(xl_part,yl,graph=True,graph_title=\"Weather Only - Random Forests - Partial\")\n",
    "end = timer()\n",
    "print(f'Random Forest Model on Data Subset Complete in {end-start} seconds')\n",
    "\n",
    "start = timer()\n",
    "boost_accuracy_full,boo_auc_full = run_cross_validation_on_classification_Boost(xl_full,yl,graph=True,graph_title=\"Weather Only - Boosted Trees - Full\")\n",
    "end = timer()\n",
    "print(f'Boosted Trees Model on Full Dataset Complete in {end-start} seconds')\n",
    "\n",
    "start = timer()\n",
    "boost_accuracy_part,boo_auc_part = run_cross_validation_on_classification_Boost(xl_part,yl,graph=True,graph_title=\"Weather Only - Boosted Trees - Partial\")\n",
    "end = timer()\n",
    "print(f'Boosted Trees Model on Data Subset Complete in {end-start} seconds')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73e54932",
   "metadata": {},
   "outputs": [],
   "source": [
    "#create a data frame of the results for analysis\n",
    "result_aa_list  = [['Logistic Run 1','Full',log_accuracy_full,log_auc_full]\n",
    "                  ,['Logistic Run 2','Partial',log_accuracy_part,log_auc_part]\n",
    "                  ,['RDA Run 1','Full',rda_accuracy_full,rda_auc_full]\n",
    "                  ,['RDA Run 2','Partial',rda_accuracy_part,rda_auc_part]\n",
    "                  ,['Random Forest Run 1','Partial',rf_accuracy_part,rf_auc_part]\n",
    "                  ,['Boosted Trees Run 1','Full',boost_accuracy_full,boo_auc_full]\n",
    "                  ,['Boosted Trees Run 2','Partial',boost_accuracy_part.boo_auc_part]]\n",
    "results_above_average = pd.DataFrame(result_aa_list,columns=['Model','Dataset','Accuracy','AUC'])\n",
    "sort_results = results_above_average.sort_values(['AUC','Accuracy'],ascending=[False,False])\n",
    "sort_results.to_excel('RQ1_Ticket_Classification.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d736f8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "full_end = timer()\n",
    "print(f'Total elapsed time {(full_end-full_start)/60}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
